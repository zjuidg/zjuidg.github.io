[ {
  "id": "stringlineEva",
  "paper": "",
  "teaser": "source/projects/stringlineEva/stringlineEva.png",
  "title": "A Comparative Study on Fixed-order Event Sequence Visualizations: Gantt, Extended Gantt, and Stringline Charts",
  "authors": ["Junxiu Tang", "Fumeng Yang", "Jiang Wu", "Yifang Wang", "Jiayi Zhou", "Xiwen Cai", "Lingyun Yu", "Yingcai Wu"],
  "source": "IEEE TVCG",
  "transaction": "IEEE Transactions on Visualization and Computer Graphics",
  "year": 2024,
  "abstract": "",
  "video": "",
  "volume": 0,
  "issue": 0,
  "page": [0,0],
  "demo": "",
  "DOI": "10.1109/TVCG.2024.3358919"
},{
  "id": "TableIllustrator",
  "title": "Table Illustrator: Puzzle-based interactive authoring of plain tables",
  "teaser": "source/projects/TableIllustrator/TableIllustrator.png",
  "authors": [
    "Yanwei Huang", "Yurun Yang", "Xinhuan Shu", "Ran Chen", "Di Weng", "Yingcai Wu"
  ],
  "source": "CHI",
  "transaction": "The ACM CHI Conference on Human Factors in Computing Systems (CHI 2024)",
  "year": 2024,
  "video": "",
  "embedVideo": "",
  "abstract": "",
  "paper": "",
  "doi":"10.1145/3613904.3642415"
},{
  "id": "OptiMuse",
  "title": "Understanding Nonlinear Collaboration between Human and AI Agents: A Co-design Framework for Creative Design",
  "teaser": "source/projects/OptiMuse/OptiMuse.png",
  "authors": [
    "Jiayi Zhou", "Renzhong Li", "Junxiu Tang", "Tan Tang", "Haotian Li", "Weiwei Cui", "Yingcai Wu"
  ],
  "source": "CHI",
  "transaction": "The ACM CHI Conference on Human Factors in Computing Systems (CHI 2024)",
  "year": 2024,
  "video": "",
  "embedVideo": "",
  "abstract": "",
  "paper": ""
},{
    "id": "VAID",
    "title": "VAID: Indexing View Designs in Visual Analytics System",
    "teaser": "source/projects/VAID/VAID.png",
    "authors": [
      "Lu Ying","Aoyu Wu", "Haotian Li", "Zikun Deng", "Ji Lan", "Jiang Wu", "Yong Wang", "Huamin Qu", "Dazhen Deng", "Yingcai Wu"
    ],
    "source": "CHI",
    "transaction": "The ACM CHI Conference on Human Factors in Computing Systems (CHI 2024)",
    "year": 2024,
    "video": "",
    "embedVideo": "",
    "abstract": "",
    "paper": ""
  },{
    "id": "VolleyNaut",
    "paper": "",
    "teaser": "source/projects/VolleyNaut/volleynaut.png",
    "title": "VolleyNaut: Pioneering Immersive Training for Inclusive Sitting Volleyball Skill Development",
    "video": "",
    "embedVideo": "",
    "authors": ["Ut Gong", "Hanze Jia", "Yujie Wang", "Tan Tang", "Xiao Xie", "Yingcai Wu"],
    "source": "VR",
    "transaction": "IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES(IEEE VR 2024)",
    "year": 2024,
    "abstract": "",
    "DOI": ""
  },{
    "id": "JsonCurer",
    "paper": "",
    "teaser": "source/projects/JsonCurer/JsonCurer.png",
    "title": "JsonCurer: Data Quality Management for JSON Based on an Aggregated Schema",
    "DOI": "",
    "authors": ["Kai Xiong" , "Xinyi Xu", "Siwei Fu" , "Di Weng" , "Yongheng Wang" , "Yingcai Wu"],
    "source": "PacificVis",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE Pacific Visualization 2024)",
    "year": 2024,
    "abstract": "",
    "video": "",
    "embedVideo": "",
    "volume": 0,
    "issue": 0,
    "page": [0,0],
    "demo": ""
  },
  {
    "id": "TacPrint",
    "paper": "",
    "teaser": "source/projects/TacPrint/TacPrint.png",
    "title": "TacPrint: Visualizing the Biomechanical Fingerprint in Table Tennis",
    "DOI": "",
    "authors": ["Jiachen Wang", "Ji Ma", "Zheng Zhou", "Xiao Xie", "Hui Zhang", "Yingcai Wu", "Huamin Qu"],
    "source": "PacificVis",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE Pacific Visualization 2024)",
    "year": 2024,
    "abstract": "",
    "video": "",
    "embedVideo": "",
    "volume": 0,
    "issue": 0,
    "page": [0,0],
    "demo": ""
  },
  {
    "id": "GeoChron",
    "paper": "source/projects/GeoChron/GeoChron.pdf",
    "teaser": "source/projects/GeoChron/GeoChron.png",
    "title": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "DOI": "",
    "authors": ["Zikun Deng", "Shifu Chen", "Tobias Schreck", "Dazhen Deng", "Tan Tang", "Mingliang Xu", "Di Weng", "Yingcai Wu"],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2023)",
    "year": 2023,
    "abstract": "In geo-related fields such as urban informatics, atmospheric science, and geography, large-scale spatial time (ST) series (i.e., geo-referred time series) are collected for monitoring and understanding important spatiotemporal phenomena. ST series visualization is an effective means of understanding the data and reviewing spatiotemporal phenomena, which is a prerequisite for in-depth data analysis. However, visualizing these series is challenging due to their large scales, inherent dynamics, and spatiotemporal nature. In this study, we introduce the notion of patterns of evolution in ST series. Each evolution pattern is characterized by 1) a set of ST series that are close in space and 2) a time period when the trends of these ST series are correlated. We then leverage Storyline techniques by considering an analogy between evolution patterns and sessions, and finally design a novel visualization called GeoChron, which is capable of visualizing large-scale ST series in an evolution pattern-aware and narrative-preserving manner. GeoChron includes a mining framework to extract evolution patterns and two-level visualizations to enhance its visual scalability. We evaluate GeoChron with two case studies, an informal user study, an ablation study, parameter analysis, and running time analysis.",
    "video": "https://youtu.be/jc7aeiszPQM",
    "embedVideo": "https://www.youtube.com/embed/jc7aeiszPQM",
    "volume": 1,
    "issue": 1,
    "page": [1,11],
    "demo": ""
  },
  {
    "id": "ArEnhanced",
    "paper": "source/projects/ArEnhanced/ArEnhanced.pdf",
    "teaser": "source/projects/ArEnhanced/ArEnhanced.png",
    "title": "AR-Enhanced Workouts: Exploring Visual Cues for At-Home Workout Videos in AR Environment",
    "video": "https://youtu.be/KdV6RJzOh6c",
    "embedVideo": "https://www.youtube.com/embed/KdV6RJzOh6c",
    "authors": [
      "Yihong Wu",
      "Lingyun Yu",
      "Jie Xu",
      "Dazhen Deng",
      "Jiachen Wang",
      "Xiao Xie",
      "Hui Zhang",
      "Yingcai Wu"
    ],
    "source": "UIST",
    "transaction": "ACM Symposium on User Interface Software and Technology (UIST 2023)",
    "year": 2023,
    "abstract": "In recent years, with growing health consciousness, at-home workout has become increasingly popular for its convenience and safety. Most people choose to follow video guidance during exercising. However, our preliminary study revealed that fitness-minded people face challenges when watching exercise videos on handheld devices or fixed monitors, such as limited movement comprehension due to static camera angles and insufficient feedback. To address these issues, we reviewed popular workout videos, identified user requirements, and came up with an augmented reality (AR) solution. Following a user-centered iterative design process, we proposed a design space of AR visual cues for workouts and implemented an AR-based application. Specifically, we captured usersâ€™ exercise performance with pose-tracking technology and provided feedback via AR visual cues. Two user experiments showed that incorporating AR visual cues could improve movement comprehension and enable users to adjust their movements based on real-time feedback. Finally, we presented several suggestions to inspire future design and apply AR visual cues to sports training.",
    "DOI": ""
  },
  {
    "id": "PColorizor",
    "paper": "source/projects/PColorizor/PColorizor.pdf",
    "teaser": "source/projects/PColorizor/PColorizor.png",
    "title": "PColorizor: Re-coloring Ancient Chinese Paintings with Ideorealm-congruent Poems",
    "video": "https://www.youtube.com/watch?v=CNbNIoDh1WE",
    "embedVideo": "https://www.youtube.com/embed/CNbNIoDh1WE",
    "authors": [
      "Tan Tang",
      "Yanhong Wu",
      "Peiquan Xia",
      "Wange Wu",
      "Xiaosong Wang",
      "Yingcai Wu"
    ],
    "source": "UIST",
    "transaction": "ACM Symposium on User Interface Software and Technology (UIST 2023)",
    "year": 2023,
    "abstract": "Color restoration of ancient Chinese paintings plays a significant role in Chinese culture protection and inheritance. However, traditional color restoration is challenging and time-consuming because it requires professional restorers to conduct detailed literature reviews on numerous paintings for reference colors. After that, they have to fill in the inferred colors on the painting manually. In this paper, we present PColorizor, an interactive system that integrates advanced deep-learning models and novel visualizations to ease the difficulties of color restoration. PColorizor is established on the principle of poem-painting congruence. Given a color-faded painting, we employ both explicit and implicit color guidance implied by ideorealm-congruent poems to associate reference paintings. We propose a mountain-like visualization to facilitate efficient navigation of the color schemes extracted from the reference paintings. This visual representation allows users to easily see the color distribution over time at both the ideorealm and imagery levels. Moreover, we demonstrate the ideorealm understood by deep learning models through visualizations to bridge the communication gap between human restorers and deep learning models. We also adopt intelligent color-filling techniques to accelerate manual color restoration further. To evaluate PColorizor, we collaborate with domain experts to conduct two case studies to collect their feedback. The results suggest that PColorizor could be beneficial in enabling the effective restoration of color-faded paintings.",
    "DOI": ""
  },
  {
    "id": "Questionnaire",
    "paper": "source/projects/Questionnaire/Questionnaire.pdf",
    "teaser": "source/projects/Questionnaire/Questionnaire.png",
    "title": "Causality-Based Visual Analysis of Questionnaire Responses",
    "video": "https://youtu.be/bYH2A-aSB98",
    "embedVideo": "https://www.youtube.com/embed/bYH2A-aSB98",
    "authors": [
      "Renzhong Li",
      "Weiwei Cui",
      "Tianqi Song",
      "Xiao Xie",
      "Rui Ding",
      "Yun Wang",
      "Haidong Zhang",
      "Hong Zhou",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2023)",
    "year": 2023,
    "abstract": "As the final stage of questionnaire analysis, causal reasoning is the key to turning responses into valuable insights and actionable items for decision-makers. During the questionnaire analysis, classical statistical methods (e.g., Differences-in-Differences) have been widely exploited to evaluate causality between questions. However, due to the huge search space and complex causal structure in data, causal reasoning is still extremely challenging and time-consuming, and often conducted in a trial-and-error manner. On the other hand, existing visual methods of causal reasoning face the challenge of bringing scalability and expert knowledge together and can hardly be used in the questionnaire scenario. In this work, we present a systematic solution to help analysts effectively and efficiently explore questionnaire data and derive causality. Based on the association mining algorithm, we dig question combinations with potential inner causality and help analysts interactively explore the causal sub-graph of each question combination. Furthermore, leveraging the requirements collected from the experts, we built a visualization tool and conducted a comparative study with the state-of-the-art system to show the usability and efficiency of our system.",
    "volume": 1,
    "issue": 1,
    "page": [
      1,
      11
    ],
    "DOI": ""
  },
  {
    "id": "ActionEvaluator",
    "paper": "source/projects/ActionEvaluator/ActionEvaluator.pdf",
    "teaser": "source/projects/ActionEvaluator/ActionEvaluator.png",
    "title": "Action-Evaluator: A Visualization Approach for Player Action Evaluation in Soccer",
    "DOI": "",
    "authors": ["Anqi Cao", "Xiao Xie", "Mingxu Zhou", "Hui Zhang", "Mingliang Xu", "Yingcai Wu"],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2023)",
    "year": 2023,
    "abstract": "In soccer, player action evaluation provides a fine-grained method to analyze player performance and plays an important role in improving winning chances in future matches. However, previous studies on action evaluation only provide a score for each action, and hardly support inspecting and comparing player actions integrated with complex match context information such as team tactics and player locations. In this work, we collaborate with soccer analysts and coaches to characterize the domain problems of evaluating player performance based on action scores. We design a tailored visualization of soccer player actions that places the action choice together with the tactic it belongs to as well as the player locations in the same view. Based on the design, we introduce a visual analytics system, Action-Evaluator, to facilitate a comprehensive player action evaluation through player navigation, action investigation, and action explanation. With the system, analysts can find players to be analyzed efficiently, learn how they performed under various match situations, and obtain valuable insights to improve their action choices. The usefulness and effectiveness of this work are demonstrated by two case studies on a real-world dataset and an expert interview.",
    "video": "https://www.youtube.com/watch?v=6FkF-lpMyZg",
    "embedVideo": "https://www.youtube.com/embed/6FkF-lpMyZg",
    "volume": 1,
    "issue": 1,
    "page": [1,11],
    "demo": ""
  },
  {
    "id": "MediVizor",
    "paper": "source/projects/MediVizor/MediVizor.pdf",
    "teaser": "source/projects/MediVizor/MediVizor.png",
    "title": "MediVizor: Visual Mediation Analysis of Nominal Variables",
    "authors": ["Ji Lan", "Zheng Zhou", "Xiao Xie", "Yanhong Wu", "Hui Zhang", "Yingcai Wu"],
    "source": "IEEE TVCG",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics",
    "year": 2023,
    "abstract": "Mediation analysis is crucial for diagnosing indirect causal relations in many scientific fields. However, mediation analysis of nominal variables requires examining and comparing multiple total effects and their corresponding direct/indirect causal effects derived from mediation models. This process is tedious and challenging to achieve with classical analysis tools such as Excel tables. In this study, we worked closely with experts from two scientific domains to design MediVizor, a visualization system that enables experts to conduct visual mediation analysis of nominal variables.The visualization design allows users to browse and compare multiple total effects together with the direct/indirect effects that compose them. The design also allows users to examine to what extent the positive and negative direct/indirect effects contribute to and reduce the total effects, respectively. We conducted two case studies separately with the experts from the two domains, sports and communication science, and a user study with common users to evaluate the system and design. The positive feedback from experts and common users demonstrates the effectiveness and generalizability of the system. ",
    "video": "https://youtu.be/CURaue54Uhs",
    "volume": 1,
    "issue": 1,
    "page": [1,14],
    "demo": "",
    "DOI": "10.1109/TVCG.2023.3282801"
  },
  {
    "id": "OBTracker",
    "titleKey": [
      "Honorable Mention"
    ],
    "paper": "source/projects/OBTracker/OBTracker.pdf",
    "teaser": "source/projects/OBTracker/OBTracker.png",
    "video": "https://youtu.be/J1P2VSn8ge4",
    "embedVideo": "https://www.youtube.com/embed/J1P2VSn8ge4",
    "title": "OBTracker: Visual Analytics of Off-ball Movements in Basketball",
    "DOI": "10.1109/TVCG.2022.3209373",
    "authors": [
      "Yihong Wu",
      "Dazhen Deng",
      "Xiao Xie",
      "Moqi He",
      "Jie Xu",
      "Hongzeng Zhang",
      "Hui Zhang",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2022)",
    "year": 2022,
    "abstract": "In a basketball play, players who are not in possession of the ball (i.e., off-ball players) can still effectively contribute to the team's offense, such as making a sudden move to create scoring opportunities. Analyzing the movements of off-ball players can thus facilitate the development of effective strategies for coaches. However, common basketball statistics (e.g., points and assists) primarily focus on what happens around the ball and are mostly result-oriented, making it challenging to objectively assess and fully understand the contributions of off-ball movements. To address these challenges, we collaborate closely with domain experts and summarize the multi-level requirements for off-ball movement analysis in basketball. We first establish an assessment model to quantitatively evaluate the offensive contribution of an off-ball movement considering both the position of players and the team cooperation. Based on the model, we design and develop a visual analytics system called OBTracker to support the multifaceted analysis of off-ball movements. OBTracker enables users to identify the frequency and effectiveness of off-ball movement patterns and learn the performance of different off-ball players. A tailored visualization based on the Voronoi diagram is proposed to help users interpret the contribution of off-ball movements from a temporal perspective. We conduct two case studies based on the tracking data from NBA games and demonstrate the effectiveness and usability of OBTracker through expert feedback.",
    "volume": 1,
    "issue": 1,
    "page": [
      1,
      11
    ]
  },
  {
    "id": "GeoNetverse",
    "paper": "source/projects/GeoNetverse/GeoNetverse.pdf",
    "teaser": "source/projects/GeoNetverse/GeoNetverse.png",
    "title": "Multilevel Visual Analysis of Aggregate Geo-Networks",
    "DOI": "10.1109/TVCG.2022.3229953",
    "authors": ["Zikun Deng", "Shifu Chen", "Xiao Xie", "Guodao Sun", "Mingliang Xu", "Di Weng", "Yingcai Wu"],
    "source": "IEEE TVCG",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics",
    "year": 2023,
    "abstract": "Numerous patterns found in urban phenomena, such as air pollution and human mobility, can be characterized as many directed geospatial networks (geo-networks) that represent spreading processes in urban space. These geo-networks can be analyzed from multiple levels, ranging from the macro-level of summarizing all geo-networks, meso-level of comparing or summarizing parts of geo-networks, and micro-level of inspecting individual geo-networks. Most of the existing visualizations cannot support multilevel analysis well. These techniques work by: 1) showing geo-networks separately with multiple maps leads to heavy context switching costs between different maps; 2) summarizing all geo-networks into a single network can lead to the loss of individual information; 3) drawing all geo-networks onto one map might suffer from the visual scalability issue in distinguishing individual geo-networks. In this study, we propose GeoNetverse, a novel visualization technique for analyzing aggregate geo-networks from multiple levels. Inspired by metro maps, GeoNetverse balances the overview and details of the geo-networks by placing the edges shared between geo-networks in a stacked manner. To enhance the visual scalability, GeoNetverse incorporates a level-of-detail rendering, a progressive crossing minimization, and a coloring technique. A set of evaluations was conducted to evaluate GeoNetverse from multiple perspectives.",
    "video": "https://www.youtube.com/watch?v=-GXWCpf9oqY",
    "volume": 1,
    "issue": 1,
    "page": [1,16],
    "demo": ""
  },
  {
    "id": "CompositeVisualization",
    "paper": "source/projects/CompositeVisualization/CompositeVisualization.pdf",
    "teaser": "source/projects/CompositeVisualization/CompositeVisualization.png",
    "video": "",
    "embedVideo": "",
    "title": "Revisiting the Design Patterns of Composite Visualizations",
    "DOI": "10.1109/TVCG.2022.3213565",
    "authors": ["Dazhen Deng", "Weiwei Cui", "Xiyu Meng", "Mengye Xu", "Yu Liao", "Haidong Zhang", "Yingcai Wu"],
    "source": "IEEE TVCG",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics",
    "year": 2022,
    "abstract": "Composite visualization is a popular design strategy that represents complex datasets by integrating multiple visualizations in a meaningful and aesthetic layout, such as juxtaposition, overlay, and nesting. With this strategy, numerous novel designs have been proposed in visualization publications to accomplish various visual analytic tasks. However, there is a lack of understanding of design patterns of composite visualization, thus failing to provide holistic design space and concrete examples for practical use. In this paper, we opted to revisit the composite visualizations in IEEE VIS publications and answered what and how visualizations of different types are composed together. To achieve this, we first constructed a corpus of composite visualizations from the publications and analyzed common practices, such as the pattern distributions and co-occurrence of visualization types. From the analysis, we obtained insights into different design patterns on the utilities and their potential pros and cons. Furthermore, we discussed usage scenarios of our taxonomy and corpus and how future research on visualization composition can be conducted on the basis of this study.",
    "volume": 1,
    "issue": 1,
    "page": [
      1,
      16
    ],
    "demo": "https://composite-visualizations.github.io"
  },
  {
    "id": "ECoalVis",
    "paper": "source/projects/ECoalVis/ECoalVis.pdf",
    "teaser": "source/projects/ECoalVis/ECoalVis.png",
    "video": "https://youtu.be/XsqdJd2y6Z0",
    "embedVideo": "https://www.youtube.com/embed/XsqdJd2y6Z0",
    "title": "ECoalVis: Visual Analysis of Control Strategies in Coal-fired Power Plants",
    "DOI": "10.1109/TVCG.2022.3209430",
    "authors": [
      "Shuhan Liu",
      "Di Weng",
      "Yuan Tian",
      "Zikun Deng",
      "Haoran Xu",
      "Xiangyu Zhu",
      "Honglei Yin",
      "Xianyuan Zhan",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2022)",
    "year": 2022,
    "abstract": "Improving the efficiency of coal-fired power plants has numerous benefits. The control strategy is one of the major factors affecting such efficiency. However, due to the complex and dynamic environment inside the power plants, it is hard to extract and evaluate control strategies and their cascading impact across massive sensors. Existing manual and data-driven approaches cannot well support the analysis of control strategies because these approaches are time-consuming and do not scale with the complexity of the power plant systems. Three challenges were identified: a) interactive extraction of control strategies from large-scale dynamic sensor data, b) intuitive visual representation of cascading impact among the sensors in a complex power plant system, and c) time-lag-aware analysis of the impact of control strategies on electricity generation efficiency. By collaborating with energy domain experts, we addressed these challenges with ECoalVis, a novel interactive system for experts to visually analyze the control strategies of coal-fired power plants extracted from historical sensor data. The effectiveness of the proposed system is evaluated with two usage scenarios on a real-world historical dataset and received positive feedback from experts.",
    "volume": 1,
    "issue": 1,
    "page": [
      1,
      11
    ]
  },
  {
    "id": "TacTrainer",
    "paper": "source/projects/TacTrainer/TacTrainer.pdf",
    "teaser": "source/projects/TacTrainer/TacTrainer.png",
    "video": "https://youtu.be/nriqaQUjZ1E",
    "embedVideo": "https://www.youtube.com/embed/nriqaQUjZ1E",
    "title": "Tac-Trainer: A Visual Analytics System for IoT-based Racket Sports Training",
    "DOI": "10.1109/TVCG.2022.3209352",
    "authors": [
      "Jiachen Wang",
      "Ji Ma",
      "Kangping Hu",
      "Zheng Zhou",
      "Hui Zhang",
      "Xiao Xie",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2022)",
    "year": 2022,
    "abstract": "Conventional racket sports training highly relies on coaches' knowledge and experience, leading to biases in the guidance. To solve this problem, smart wearable devices based on Internet of Things technology (IoT) have been extensively investigated to support data-driven training. Considerable studies introduced methods to extract valuable information from the sensor data collected by IoT devices. However, the information cannot provide actionable insights for coaches due to the large data volume and high data dimensions. We proposed an IoT + VA framework, Tac-Trainer, to integrate the sensor data, the information, and coaches' knowledge to facilitate racket sports training. Tac-Trainer consists of four components: device configuration, data interpretation, training optimization, and result visualization. These components collect trainees' kinematic data through IoT devices, transform the data into attributes and indicators, generate training suggestions, and provide an interactive visualization interface for exploration, respectively. We further discuss new research opportunities and challenges inspired by our work from two perspectives, VA for IoT and IoT for VA.",
    "volume": 1,
    "issue": 1,
    "page": [
      1,
      11
    ]
  },
  {
    "id": "MetaGlyph",
    "paper": "source/projects/MetaGlyph/MetaGlyph.pdf",
    "teaser": "source/projects/MetaGlyph/MetaGlyph.png",
    "video": "https://youtu.be/E_68JwZmlcY",
    "embedVideo": "https://www.youtube.com/embed/E_68JwZmlcY",
    "title": "MetaGlyph: Automatic Generation of Metaphoric Glyph-based Visualization",
    "DOI": "10.1109/TVCG.2022.3209447",
    "authors": [
      "Lu Ying",
      "Xinhuan Shu",
      "Dazhen Deng",
      "Yuchen Yang",
      "Tan Tang",
      "Lingyun Yu",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2022)",
    "year": 2022,
    "abstract": "Glyph-based visualization achieves an impressive graphic design when associated with comprehensive visual metaphors, which help audiences effectively grasp the conveyed information through revealing data semantics. However, creating such metaphoric glyph-based visualization (MGV) is not an easy task, as it requires not only a deep understanding of data but also professional design skills. This paper proposes MetaGlyph, an automatic system for generating MGVs from a spreadsheet. To develop MetaGlyph, we first conduct a qualitative analysis to understand the design of current MGVs from the perspectives of metaphor embodiment and glyph design. Based on the results, we introduce a novel framework for generating MGVs by metaphoric image selection and an MGV construction. Specifically, MetaGlyph automatically selects metaphors with corresponding images from online resources based on the input data semantics. We then integrate a Monte Carlo tree search algorithm that explores the design of an MGV by associating visual elements with data dimensions given the data importance, semantic relevance, and glyph non-overlap. The system also provides editing feedback that allows users to customize the MGVs according to their design preferences. We demonstrate the use of MetaGlyph through a set of examples, one usage scenario, and validate its effectiveness through a series of expert interviews.",
    "volume": 1,
    "issue": 1,
    "page": [
      1,
      11
    ]
  },
  {
    "id": "DashBot",
    "paper": "source/projects/DashBot/DashBot.pdf",
    "teaser": "source/projects/DashBot/DashBot.png",
    "video": "https://youtu.be/hM4XMU7pv-0",
    "embedVideo": "https://www.youtube.com/embed/hM4XMU7pv-0",
    "title": "DashBot: Insight-Driven Dashboard Generation Based on Deep Reinforcement Learning",
    "DOI": "10.1109/TVCG.2022.3209468",
    "authors": [
      "Dazhen Deng",
      "Aoyu Wu",
      "Huamin Qu",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2022)",
    "year": 2022,
    "abstract": "Analytical dashboards are popular in business intelligence to facilitate insight discovery with multiple charts. However, creating an effective dashboard is highly demanding, which requires users to have adequate data analysis background and be familiar with professional tools, such as Power BI. To create a dashboard, users have to configure charts by selecting data columns and exploring different chart combinations to optimize the communication of insights, which is trial-and-error. Recent research has started to use deep learning methods for dashboard generation to lower the burden of visualization creation. However, such efforts are greatly hindered by the lack of large-scale and high-quality datasets of dashboards. In this work, we propose using deep reinforcement learning to generate analytical dashboards that can use well-established visualization knowledge and the estimation capacity of reinforcement learning. Specifically, we use visualization knowledge to construct a training environment and rewards for agents to explore and imitate human exploration behavior with a well-designed agent network. The usefulness of the deep reinforcement learning model is demonstrated through ablation studies and user studies. In conclusion, our work opens up new opportunities to develop effective ML-based visualization recommenders without beforehand training datasets.",
    "volume": 1,
    "issue": 1,
    "page": [
      1,
      11
    ],
    "demo": "https://github.com/dengdazhen/DashBot"
  },
  {
    "id": "Rasipam",
    "paper": "source/projects/Rasipam/Rasipam.pdf",
    "teaser": "source/projects/Rasipam/Rasipam.png",
    "video": "https://youtu.be/hsOZEcwZtCc",
    "embedVideo": "https://www.youtube.com/embed/hsOZEcwZtCc",
    "title": "RASIPAM: Interactive Pattern Mining of Multivariate Event Sequences in Racket Sports",
    "DOI": "10.1109/TVCG.2022.3209452",
    "authors": [
      "Jiang Wu",
      "Dongyu Liu",
      "Ziyang Guo",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transaction on Visualization and Computer Graphics (IEEE VIS 2022)",
    "year": 2022,
    "abstract": "Experts in racket sports like tennis and badminton use tactical analysis to gain insight into competitors' playing styles. Many data-driven methods apply pattern mining to racket sports data - which is often recorded as multivariate event sequences - to uncover sports tactics. However, tactics obtained in this way are often inconsistent with those deduced by experts through their domain knowledge, which can be confusing to those experts. This work introduces RASIPAM, a RAcket-Sports Interactive PAttern Mining system, which allows experts to incorporate their knowledge into data mining algorithms to discover meaningful tactics interactively. RASIPAM consists of a constraint-based pattern mining algorithm that responds to the analysis demands of experts: Experts provide suggestions for finding tactics in intuitive written language, and these suggestions are translated into constraints to run the algorithm. RASIPAM further introduces a tailored visual interface that allows experts to compare the new tactics with the original ones and decide whether to apply a given adjustment. This interactive workflow iteratively progresses until experts are satisfied with all tactics. We conduct a quantitative experiment to show that our algorithm supports real-time interaction. Two case studies in tennis and in badminton respectively, each involving two domain experts, are conducted to show the effectiveness and usefulness of the system.",
    "demo": "https://github.com/Rasipam/Rasipam"
  },
  {
    "id": "COMANTICS",
    "paper": "source/projects/COMANTICS/COMANTICS.pdf",
    "teaser": "source/projects/COMANTICS/COMANTICS.png",
    "video": "https://youtu.be/acVSqJQ3jnQ",
    "embedVideo": "https://www.youtube.com/embed/acVSqJQ3jnQ",
    "title": "Revealing the Semantics of Data Wrangling Scripts With COMANTICS",
    "DOI": "10.1109/TVCG.2022.3209470",
    "authors": [
      "Kai Xiong",
      "Zhongsu Luo",
      "Siwei Fu",
      "Yongheng Wang",
      "Mingliang Xu",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2022)",
    "year": 2022,
    "abstract": "Data workers usually seek to understand the semantics of data wrangling scripts in various scenarios, such as code debugging, reusing, and maintaining. However, the understanding is challenging for novice data workers due to the variety of programming languages, functions, and parameters. Based on the observation that differences between input and output tables highly relate to the type of data transformation, we outline a design space including 103 characteristics to describe table differences. Then, we develop COMANTICS, a three-step pipeline that automatically detects the semantics of data transformation scripts. The first step focuses on the detection of table differences for each line of wrangling code. Second, we incorporate a characteristic-based component and a Siamese convolutional neural network-based component for the detection of transformation types. Third, we derive the parameters of each data transformation by employing a \"slot filling\" strategy. We design experiments to evaluate the performance of COMANTICS. Further, we assess its flexibility using three example applications in different domains."
  },
  {
    "id": "PuzzleFixer",
    "paper": "source/projects/PuzzleFixer/PuzzleFixer.pdf",
    "teaser": "source/projects/PuzzleFixer/PuzzleFixer.png",
    "video": "https://youtu.be/Djho5RjXXJ4",
    "embedVideo": "https://www.youtube.com/embed/Djho5RjXXJ4",
    "title": "PuzzleFixer: A Visual Reassembly System for Immersive Fragments Restoration",
    "DOI": "10.1109/TVCG.2022.3209388",
    "authors": [
      "Shuainan Ye",
      "Zhutian Chen",
      "Xiangtong Chu",
      "Kang Li",
      "Juntong Luo",
      "Yi Li",
      "Guohua Geng",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2022)",
    "year": 2022,
    "abstract": "We present PuzzleFixer, an immersive interactive system for experts to rectify defective reassembled 3D objects. Reassembling the fragments of a broken object to restore its original state is the prerequisite of many analytical tasks such as cultural relics analysis and forensics reasoning. While existing computer-aided methods can automatically reassemble fragments, they often derive incorrect objects due to the complex and ambiguous fragment shapes. Thus, experts usually need to refine the object manually. Prior advances in immersive technologies provide benefits for realistic perception and direct interactions to visualize and interact with 3D fragments. However, few studies have investigated the reassembled object refinement. The specific challenges include: 1) the fragment combination set is too large to determine the correct matches, and 2) the geometry of the fragments is too complex to align them properly. To tackle the first challenge, PuzzleFixer leverages dimensionality reduction and clustering techniques, allowing users to review possible match categories, select the matches with reasonable shapes, and drill down to shapes to correct the corresponding faces. For the second challenge, PuzzleFixer embeds the object with node-link networks to augment the perception of match relations. Specifically, it instantly visualizes matches with graph edges and provides force feedback to facilitate the efficiency of alignment interactions. To demonstrate the effectiveness of PuzzleFixer, we conducted an expert evaluation based on two cases on real-world artifacts and collected feedback through post-study interviews. The results suggest that our system is suitable and efficient for experts to refine incorrect reassembled objects.",
    "volume": 0,
    "issue": 0,
    "page": [
      0,
      0
    ]
  },
  {
    "id": "Rigel",
    "paper": "source/projects/Rigel/Rigel.pdf",
    "teaser": "source/projects/Rigel/Rigel.png",
    "video": "https://youtu.be/fvM_W-1n7N4",
    "embedVideo": "https://www.youtube.com/embed/fvM_W-1n7N4",
    "title": "Rigel: Transforming Tabular Data by Declarative Mapping",
    "DOI": "10.1109/TVCG.2022.3209385",
    "authors": [
      "Ran Chen",
      "Di Weng",
      "Yanwei Huang",
      "Xinhuan Shu",
      "Jiayi Zhou",
      "Guodao Sun",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2022)",
    "year": 2022,
    "abstract": "We present Rigel, an interactive system for rapid transformation of tabular data. Rigel implements a new declarative mapping approach that formulates the data transformation procedure as direct mappings from data to the row, column, and cell channels of the target table. To construct such mappings, Rigel allows users to directly drag data attributes from input data to these three channels and indirectly drag or type data values in a spreadsheet, and possible mappings that do not contradict these interactions are recommended to achieve efficient and straightforward data transformation. The recommended mappings are generated by enumerating and composing data variables based on the row, column, and cell channels, thereby revealing the possibility of alternative tabular forms and facilitating open-ended exploration in many data transformation scenarios, such as designing tables for presentation. In contrast to existing systems that transform data by composing operations (like transposing and pivoting), Rigel requires less prior knowledge on these operations, and constructing tables from the channels is more efficient and results in less ambiguity than generating operation sequences as done by the traditional by-example approaches. User study results demonstrated that Rigel is significantly less demanding in terms of time and interactions and suits more scenarios compared to the state-of-the-art by-example approach. A gallery of diverse transformation cases is also presented to show the potential of Rigel's expressiveness.",
    "demo": "https://rigel-system.github.io/rigel-system/"
  },
  {
    "id": "Sporthesia",
    "paper": "source/projects/Sporthesia/Sporthesia.pdf",
    "teaser": "source/projects/Sporthesia/Sporthesia.png",
    "title": "Sporthesia: Augmenting Sports Videos Using Natural Language",
    "DOI": "10.1109/TVCG.2022.3207147",
    "authors": [
      "Zhutian Chen",
      "Qisen Yang",
      "Xiao Xie",
      "Johanna Beyer",
      "Haijun Xia",
      "Yingcai Wu",
      "Hanspeter Pfister"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2022)",
    "year": 2022,
    "abstract": "Augmented sports videos, which combine visualizations and video effects to present data in actual scenes, can communicate insights engagingly and thus have been increasingly popular for sports enthusiasts around the world. Yet, creating augmented sports videos remains a challenging task, requiring considerable time and video editing skills. On the other hand, sports insights are often communicated using natural language, such as in commentaries, oral presentations, and articles, but usually lack visual cues. Thus, this work aims to facilitate the creation of augmented sports videos by enabling analysts to directly create visualizations embedded in videos using insights expressed in natural language. To achieve this goal, we propose a three-step approach - 1) detecting visualizable entities in the text, 2) mapping these entities into visualizations, and 3) scheduling these visualizations to play with the video - and analyzed 155 sports video clips and the accompanying commentaries for accomplishing these steps. Informed by our analysis, we have designed and implemented Sporthesia, a proof-of-concept system that takes racket-based sports videos and textual commentaries as the input and outputs augmented videos. We demonstrate Sporthesia's applicability in two exemplar scenarios, i.e., authoring augmented sports videos using text and augmenting historical sports videos based on auditory comments. A technical evaluation shows that Sporthesia achieves high accuracy (F1-score of 0.9) in detecting visualizable entities in the text. An expert evaluation with eight sports analysts suggests high utility, effectiveness, and satisfaction with our language-driven authoring method and provides insights for future improvement and opportunities.",
    "volume": 1,
    "issue": 1,
    "page": [
      1,
      11
    ]
  },
  {
    "id": "TeamBuilder",
    "paper": "source/projects/TeamBuilder/TeamBuilder.pdf",
    "teaser": "source/projects/TeamBuilder/TeamBuilder.png",
    "video": "https://youtu.be/-V_Mzp_o5Vw",
    "embedVideo": "https://www.youtube.com/embed/-V_Mzp_o5Vw",
    "title": "Team-Builder: Toward More Effective Lineup Selection in Soccer",
    "DOI": "10.1109/TVCG.2022.3207147",
    "authors": [
      "Anqi Cao",
      "Ji Lan",
      "Xiao Xie",
      "Hongyu Chen",
      "Xiaolong Zhang",
      "Hui Zhang",
      "Yingcai Wu"
    ],
    "source": "IEEE TVCG",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics",
    "year": 2022,
    "abstract": "Lineup selection is an essential and important task in soccer matches. To win a match, coaches must consider various factors and select appropriate players for a planned formation. Computation-based tools have been proposed to help coaches on this complex task, but they are usually based on over-simplified models on player performances, do not support interactive analysis, and overlook the inputs by coaches. In this paper, we propose a method for visual analytics of soccer lineup selection by tackling two challenges: characterizing essential factors involved in generating optimal lineup, and supporting coach-driven visual analytics of lineup selection. We develop a lineup selection model that integrates such important factors, such as spatial regions of player actions and defensive interactions with opponent players. A visualization system, Team-Builder, is developed to help coaches control the process of lineup generation, explanation, and comparison through multiple coordinated views. The usefulness and effectiveness of our system are demonstrated by two case studies on a real-world soccer event dataset.",
    "volume": 0,
    "issue": 0,
    "page": [
      1,
      16
    ]
  },
  {
    "id": "ReVast",
    "paper": "source/projects/ReVast/ReVast.pdf",
    "teaser": "source/projects/ReVast/ReVast.png",
    "title": "In Defence of Visual Analytics Systems: Replies to Critics",
    "DOI": "10.1109/TVCG.2022.3209360",
    "authors": [
      "Aoyu Wu",
      "Dazhen Deng",
      "Furui Cheng",
      "Yingcai Wu",
      "Shixia Liu",
      "Huamin Qu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2022)",
    "year": 2022,
    "abstract": "The last decade has witnessed many visual analytics (VA) systems that make successful applications to wide-ranging domains like urban analytics and explainable AI. However, their research rigor and contributions have been extensively challenged within the visualization community. We come in defence of VA systems by contributing two interview studies for gathering critics and responses to those criticisms. First, we interview 24 researchers to collect criticisms the review comments on their VA work. Through an iterative coding and refinement process, the interview feedback is summarized into a list of 36 common criticisms. Second, we interview 17 researchers to validate our list and collect their responses, thereby discussing implications for defending and improving the scientific values and rigor of VA systems. We highlight that the presented knowledge is deep, extensive, but also imperfect, provocative, and controversial, and thus recommend reading with an inclusive and critical eye. We hope our work can provide thoughts and foundations for conducting VA research and spark discussions to promote the research field forward more rigorously and vibrantly.",
    "volume": 1,
    "issue": 1,
    "page": [
      1,
      11
    ],
    "demo": "https://re-vast.github.io/"
  },
  {
    "id": "urbanva",
    "paper": "source/projects/urbanva/urbanva.pdf",
    "teaser": "source/projects/urbanva/urbanva.png",
    "title": "A survey of urban visual analytics: advances and future directions",
    "DOI": "10.1007/s41095-022-0275-7",
    "authors": [
      "Zikun Deng",
      "Di Weng",
      "Shuhan Liu",
      "Yuan Tian",
      "Mingliang Xu",
      "Yingcai Wu"
    ],
    "source": "CVM",
    "transaction": "Computational Visual Media",
    "year": 2022,
    "abstract": "Developing effective visual analytics systems demands care in characterization of domain problems and integration of visualization techniques and computational models. Urban visual analytics has already achieved remarkable success in tackling urban problems and providing fundamental services for smart cities. To promote further academic research and assist the development of industrial urban analytics systems, we comprehensively review urban visual analytics studies from four perspectives. In particular, we identify 8 urban domains and 22 types of popular visualization, analyze 7 types of computational method, and categorize existing systems into 4 types based on their integration of visualization techniques and computational models. We conclude with potential research directions and opportunities.",
    "volume": 9,
    "issue": 1,
    "page": [
      3,
      39
    ]
  },
  {
    "id": "VisImages",
    "title": "VisImages: A Fine-Grained Expert-Annotated Visualization Dataset",
    "DOI": "10.1109/TVCG.2022.3155440",
    "teaser": "source/projects/visimages/visimages.png",
    "authors": [
      "Dazhen Deng",
      "Yihong Wu",
      "Xinhuan Shu",
      "Jiang Wu",
      "Siwei Fu",
      "Weiwei Cui",
      "Yingcai Wu"
    ],
    "source": "IEEE TVCG",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics",
    "year": 2022,
    "demo": "https://visimages.github.io/",
    "paper": "source/projects/visimages/visimages.pdf",
    "abstract": "Images in visualization publications contain rich information, e.g., novel visualization designs and implicit design patterns of visualizations. A systematic collection of these images can contribute to the community in many aspects, such as literature analysis and automated tasks for visualization. In this paper, we build and make public a dataset, VisImages, which collects 12,267 images with captions from 1,397 papers in IEEE InfoVis and VAST. Built upon a comprehensive visualization taxonomy, the dataset includes 35,096 visualizations and their bounding boxes in the images. We demonstrate the usefulness of VisImages through three use cases: 1) investigating the use of visualizations in the publications with VisImages Explorer, 2) training and benchmarking models for visualization classification, and 3) localizing visualizations in the visual analytics systems automatically."
  },
  {
    "id": "Somnus",
    "title": "Visualizing the Scripts of Data Wrangling with SOMNUS",
    "DOI": "10.1109/TVCG.2022.3144975",
    "teaser": "source/projects/Somnus/Somnus.png",
    "authors": [
      "Kai Xiong",
      "Siwei Fu",
      "Guoming Ding",
      "Zhongsu Luo",
      "Rong Yu",
      "Wei Chen",
      "Hujun Bao",
      "Yingcai Wu"
    ],
    "source": "IEEE TVCG",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics",
    "year": 2022,
    "paper": "source/projects/Somnus/Somnus.pdf",
    "video": "https://youtu.be/fQ-eN_4vhso",
    "embedVideo": "https://www.youtube.com/embed/fQ-eN_4vhso",
    "abstract": "Data workers use various scripting languages for data transformation, such as SAS, R, and Python. However, understanding intricate code pieces requires advanced programming skills, which hinders data workers from grasping the idea of data transformation at ease. Program visualization is beneficial for debugging and education and has the potential to illustrate transformations intuitively and interactively. In this paper, we explore visualization design for demonstrating the semantics of code pieces in the context of data transformation. First, to depict individual data transformations, we structure a design space by two primary dimensions, i.e., key parameters to encode and possible visual channels to be mapped. Then, we derive a collection of 23 glyphs that visualize the semantics of transformations. Next, we design a pipeline, named Somnus, that provides an overview of the creation and evolution of data tables using a provenance graph. At the same time, it allows detailed investigation of individual transformations. User feedback on Somnus is positive. Our study participants achieved better accuracy with less time using Somnus, and preferred it over carefully-crafted textual description. Further, we provide two example applications to demonstrate the utility and versatility of Somnus."
  },
  {
    "id": "SimuExplorer",
    "title": "SimuExplorer: Visual Exploration of GameSimulation in Table Tennis",
    "DOI": "10.1109/TVCG.2021.3130422",
    "teaser": "source/projects/SimuExplorer/SimuExplorer.png",
    "authors": [
      "Ji Lan",
      "Zheng Zhou",
      "Jiachen Wang",
      "Hui Zhang",
      "Xiao Xie",
      "Yingcai Wu"
    ],
    "source": "IEEE TVCG",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics",
    "year": 2021,
    "paper": "source/projects/SimuExplorer/SimuExplorer.pdf",
    "abstract": "We propose SimuExplorer, a visualization system to help analysts explore how player behaviors impact scoring rates intable tennis. Such analysis is indispensable for analysts and coaches, who aim to formulate training plans that can help playersimprove. However, it is challenging to identify the impacts of individual behaviors, as well as to understand how these impacts aregenerated and accumulated gradually over the course of a game. To address these challenges, we worked closely with experts whowork for a top national table tennis team to design SimuExplorer. The SimuExplorer system integrates a Markov chain model tosimulate individual and cumulative impacts of particular behaviors. It then provides flow and matrix views to help users visualize andinterpret these impacts. We demonstrate the usefulness of the system with case studies and expert interviews. The experts think highlyof the system and have obtained insights into playersâ€™ behaviors using it."
  },
  {
    "id": "Compass",
    "title": "Compass: Towards Better Causal Analysis of Urban Time Series",
    "teaser": "source/projects/compass/compass.png",
    "authors": [
      "Zikun Deng",
      "Di Weng",
      "Xiao Xie",
      "Jie Bao",
      "Yu Zheng",
      "Mingliang Xu",
      "Wei Chen",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2021)",
    "year": 2021,
    "video": "https://youtu.be/QxvGC9F9PaY",
    "embedVideo": "https://www.youtube.com/embed/QxvGC9F9PaY",
    "paper": "source/projects/compass/compass.pdf",
    "abstract": "The spatial time series generated by city sensors allow us to observe urban phenomena like environmental pollution and traffic congestion at an unprecedented scale. However, recovering causal relations from these observations to explain the sources of urban phenomena remains a challenging task because these causal relations tend to be time-varying and demand proper time series partitioning for effective analyses. The prior approaches extract one causal graph given long-time observations, which cannot be directly applied to capturing, interpreting, and validating dynamic urban causality. This paper presents Compass, a novel visual analytics approach for in-depth analyses of the dynamic causality in urban time series. To develop Compass, we identify and address three challenges: detecting urban causality, interpreting dynamic causal relations, and unveiling suspicious causal relations. First, multiple causal graphs over time among urban time series are obtained with a causal detection framework extended from the Granger causality test. Then, a dynamic causal graph visualization is designed to reveal the time-varying causal relations across these causal graphs and facilitate the exploration of the graphs along the time. Finally, a tailored multi-dimensional visualization is developed to support the identification of spurious causal relations, thereby improving the reliability of causal analyses. The effectiveness of Compass is evaluated with two case studies conducted on the real-world urban datasets, including the air pollution and traffic speed datasets, and positive feedback was received from domain experts."
  },
  {
    "id": "OrderMonitor",
    "title": "A Visualization Approach for Monitoring Order Processing in E-Commerce Warehouse",
    "teaser": "source/projects/warehouse/warehouse.png",
    "authors": [
      "Junxiu Tang",
      "Yuhua Zhou",
      "Tan Tang",
      "Di Weng",
      "Boyang Xie",
      "Lingyun Yu",
      "Huaqiang Zhang",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2021)",
    "year": 2021,
    "video": "https://youtu.be/IanZbNr04EE",
    "embedVideo": "https://www.youtube.com/embed/IanZbNr04EE",
    "paper": "source/projects/warehouse/OrderMonitor.pdf",
    "abstract": "The efficiency of warehouses is vital to e-commerce. Fast order processing at the warehouses ensures timely deliveries and improves customer satisfaction. However, monitoring, analyzing, and manipulating order processing in the warehouses in real time are challenging for traditional methods due to the sheer volume of incoming orders, the fuzzy definition of delayed order patterns, and the complex decision-making of order handling priorities. In this paper, we adopt a data-driven approach and propose OrderMonitor, a visual analytics system that assists warehouse managers in analyzing and improving order processing efficiency in real time based on streaming warehouse event data. Specifically, the order processing pipeline is visualized with a novel pipeline design based on the sedimentation metaphor to facilitate real-time order monitoring and suggest potentially abnormal orders. We also design a novel visualization that depicts order timelines based on the Gantt charts and Mareyâ€™s graphs. Such a visualization helps the managers gain insights into the performance of order processing and find major blockers for delayed orders. Furthermore, an evaluating view is provided to assist users in inspecting order details and assigning priorities to improve the processing performance. The effectiveness of OrderMonitor is evaluated with two case studies on a real-world warehouse dataset."
  },
  {
    "id": "TIVEE",
    "title": "TIVEE: Visual Exploration and Explanation of Badminton Tactics in Immersive Visualizations",
    "teaser": "source/projects/TIVEE/TIVEE.png",
    "authors": [
      "Xiangtong Chu",
      "Xiao Xie",
      "Shuainan Ye",
      "Haolin Lu",
      "Hongguang Xiao",
      "Zeqing Yuan",
      "Zhutian Chen",
      "Hui Zhang",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2021)",
    "year": 2021,
    "paper": "source/projects/TIVEE/TIVEE.pdf",
    "video": "https://youtu.be/4j5CL5HamQQ",
    "embedVideo": "https://www.youtube.com/embed/4j5CL5HamQQ",
    "abstract": "Tactic analysis is a major issue in badminton as the effective usage of tactics is the key to win. The tactic in badminton is defined as a sequence of consecutive strokes. Most existing methods use statistical models to find sequential patterns of strokes and apply 2D visualizations such as glyphs and statistical charts to explore and analyze the discovered patterns. However, in badminton, spatial information like the shuttle trajectory, which is inherently 3D, is the core of a tactic. The lack of sufficient spatial awareness in 2D visualizations largely limited the tactic analysis of badminton. In this work, we collaborate with domain experts to study the tactic analysis of badminton in a 3D environment and propose an immersive visual analytics system, TIVEE, to assist users in exploring and explaining badminton tactics from multi-levels. Users can first explore various tactics from the third-person perspective using an unfolded visual presentation of stroke sequences. By selecting a tactic of interest, users can turn to the first-person perspective to perceive the detailed kinematic characteristics and explain its effects on the game result. The effectiveness and usefulness of TIVEE are demonstrated by case studies and an expert interview."
  },
  {
    "id": "HVSM",
    "title": "Real-Time Visual Analysis of High-Volume Social Media Posts",
    "titleKey": [
      "Honorable Mention"
    ],
    "teaser": "source/projects/HVSM/HVSM.PNG",
    "authors": [
      "Johannes Knittel",
      "Steffen Koch",
      "Tan Tang",
      "Wei Chen",
      "Yingcai Wu",
      "Shixia Liu",
      "Thomas Ertl"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2021)",
    "year": 2021,
    "abstract": "Breaking news and first-hand reports often trend on social media platforms before traditional news outlets cover them. The real-time analysis of posts on such platforms can reveal valuable and timely insights for journalists, politicians, business analysts, and first responders, but the high number and diversity of new posts pose a challenge. In this work, we present an interactive system that enables the visual analysis of streaming social media data on a large scale in real-time. We propose an efficient and explainable dynamic clustering algorithm that powers a continuously updated visualization of the current thematic landscape as well as detailed visual summaries of specific topics of interest. Our parallel clustering strategy provides an adaptive stream with a digestible but diverse selection of recent posts related to relevant topics. We also integrate familiar visual metaphors that are highly interlinked for enabling both explorative and more focused monitoring tasks. Analysts can gradually increase the resolution to dive deeper into particular topics. In contrast to previous work, our system also works with non-geolocated posts and avoids extensive preprocessing such as detecting events. We evaluated our dynamic clustering algorithm and discuss several use cases that show the utility of our system."
  },
  {
    "id": "GlyphCreator",
    "title": "GlyphCreator: Towards Example-based Automatic Generation of Circular Glyphs",
    "teaser": "source/projects/glyphcreator/glyphcreator.png",
    "authors": [
      "Lu Ying",
      "Tan Tang",
      "Luzhe Luo",
      "Lvkeshen Shen",
      "Xiao Xie",
      "Lingyun Yu",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2021)",
    "year": 2021,
    "video": "https://youtu.be/uNGJtuyniyM",
    "embedVideo": "https://www.youtube.com/embed/uNGJtuyniyM",
    "paper": "source/projects/glyphcreator/GlyphCreator.pdf",
    "abstract": "Circular glyphs are used across disparate fields to represent multidimensional data. However, although these glyphs are extremely effective, creating them is often laborious, even for those with professional design skills. This paper presents GlyphCreator, an interactive tool for the example-based generation of circular glyphs. Given an example circular glyph and multidimensional input data, GlyphCreator promptly generates a list of design candidates, any of which can be edited to satisfy the requirements of a particular representation. To develop GlyphCreator, we first derive a design space of circular glyphs by summarizing relationships between different visual elements. With this design space, we build a circular glyph dataset and develop a deep learning model for glyph parsing. The model can deconstruct a circular glyph bitmap into a series of visual elements. Next, we introduce an interface that helps users bind the input data attributes to visual elements and customize visual styles. We evaluate the parsing model through a quantitative experiment, demonstrate the use of GlyphCreator through two use scenarios, and validate its effectiveness through user interviews."
  },
  {
    "id": "VideoModerator",
    "title": "VideoModerator: A Risk-aware Framework for Multimodal Video Moderation in E-Commerce",
    "teaser": "source/projects/videomoderator/videomoderator.png",
    "authors": [
      "Tan Tang",
      "Yanhong Wu",
      "Lingyun Yu",
      "Hongyu Li",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2021)",
    "year": 2021,
    "paper": "source/projects/videomoderator/VideoModerator.pdf",
    "demo": "https://videomoderator.github.io/",
    "abstract": "Video moderation, which refers to remove deviant or explicit content from e-commerce livestreams, has become prevalent owing to social and engaging features. However, this task is tedious and time consuming due to the difficulties associated with watching and reviewing multimodal video content, including video frames and audio clips. To ensure effective video moderation, we propose VideoModerator, a risk-aware framework that seamlessly integrates human knowledge with machine insights. This framework incorporates a set of advanced machine learning models to extract the risk-aware features from multimodal video content and discover potentially deviant videos. Moreover, this framework introduces an interactive visualization interface with three views, namely, a video view, a frame view, and an audio view. In the video view, we adopt a segmented timeline and highlight high-risk periods that may contain deviant information. In the frame view, we present a novel visual summarization method that combines risk-aware features and video context to enable quick video navigation. In the audio view, we employ a storyline-based design to provide a multi-faceted overview which can be used to explore audio content. Furthermore, we report the usage of VideoModerator through a case scenario and conduct experiments and a controlled user study to validate its effectiveness."
  },
  {
    "id": "AcademicCareerSuccess",
    "title": "Seek for Success: A Visualization Approach for Understanding the Dynamics of Academic Careers",
    "teaser": "source/projects/ssuccess/ssuccess.png",
    "authors": [
      "Yifang Wang",
      "Tai-Quan Peng",
      "Huihua Lu",
      "Haoren Wang",
      "Xiao Xie",
      "Huamin Qu",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2021)",
    "year": 2021,
    "video": "https://youtu.be/S-_JopzBY6g",
    "embedVideo": "https://www.youtube.com/embed/S-_JopzBY6g",
    "paper": "source/projects/ssuccess/acseeker.pdf",
    "abstract": "How to achieve academic career success has been a long-standing research question in social science research. With the growing availability of large-scale well-documented academic profiles and career trajectories, scholarly interest in career success has been reinvigorated, which has emerged to be an active research domain called the Science of Science (i.e., SciSci). In this study, we adopt an innovative dynamic perspective to examine how individual and social factors will influence career success over time. We propose ACSeeker, an interactive visual analytics approach to explore the potential factors of success and how the influence of multiple factors changes at different stages of academic careers. We first applied a Multi-factor Impact Analysis framework to estimate the effect of different factors on academic career success over time. We then developed a visual analytics system to understand the dynamic effects interactively. A novel timeline is designed to reveal and compare the factor impacts based on the whole population. A customized career line showing the individual career development is provided to allow a detailed inspection. To validate the effectiveness and usability of ACSeeker, we report two case studies and interviews with a social scientist and general researchers."
  },
  {
    "id": "VisCommentator",
    "title": "Augmenting Sports Videos with VisCommentator",
    "titleKey": [
      "Honorable Mention"
    ],
    "teaser": "source/projects/viscommentator/viscommentator.PNG",
    "paper": "source/projects/viscommentator/viscommentator.pdf",
    "authors": [
      "Zhutian Cheng",
      "Shuainan Ye",
      "Xiangtong Chu",
      "Haijun Xia",
      "Hui Zhang",
      "Huamin Qu",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2021)",
    "year": 2021,
    "video": "https://youtu.be/bjDKygYBnPw",
    "embedVideo": "https://www.youtube.com/embed/bjDKygYBnPw",
    "abstract": "Visualizing data in sports videos is gaining traction in sports analytics, given its ability to communicate insights and explicate player strategies engagingly. However, augmenting sports videos with such data visualizations is challenging, especially for sports analysts, as it requires considerable expertise in video editing. To ease the creation process, we present a design space that characterizes augmented sports videos at an element-level (what the constituents are) and clip-level (how those constituents are organized). We do so by systematically reviewing 233 examples of augmented sports videos collected from TV channels, teams, and leagues. The design space guides selection of data insights and visualizations for various purposes. Informed by the design space and close collaboration with domain experts, we design VisCommentator, a fast prototyping tool, to eases the creation of augmented table tennis videos by leveraging machine learning-based data extractors and design space-based visualization recommendations. With VisCommentator, sports analysts can create an augmented video by selecting the data to visualize instead of manually drawing the graphical marks. Our system can be generalized to other racket sports (e.g., tennis, badminton) once the underlying datasets and models are available. A user study with seven domain experts shows high satisfaction with our system, confirms that the participants can reproduce augmented sports videos in a short period, and provides insightful implications into future improvements and opportunities."
  },
  {
    "id": "TacticFlow",
    "title": "TacticFlow: Visual Analytics of Ever-Changing Tactics in Racket Sports",
    "teaser": "source/projects/tacticflow/tacticflow.jpg",
    "authors": [
      "Jiang Wu",
      "Dongyu Liu",
      "Ziyang Guo",
      "Qingyang Xu",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VIS 2021)",
    "year": 2021,
    "video": "https://youtu.be/gzB4w9M7AFE",
    "embedVideo": "https://www.youtube.com/embed/gzB4w9M7AFE",
    "paper": "source/projects/tacticflow/tacticflow.pdf",
    "abstract": "Event sequence mining is often used to summarize patterns from hundreds of sequences but faces special challenges when handling racket sports data. In racket sports (e.g., tennis and badminton), a player hitting the ball is considered a multivariate event consisting of multiple attributes (e.g., hit technique and ball position). A rally (i.e., a series of consecutive hits beginning with one player serving the ball and ending with one player winning a point) thereby can be viewed as a multivariate event sequence. Mining frequent patterns and depicting how patterns change over time is instructive and meaningful to players who want to learn more short-term competitive strategies (i.e., tactics) that encompass multiple hits. However, players in racket sports usually change their tactics rapidly according to the opponentâ€™s reaction, resulting in ever-changing tactic progression. In this work, we introduce a tailored visualization system built on a novel multivariate sequence pattern mining algorithm to facilitate explorative identification and analysis of various tactics and tactic progression. The algorithm can mine multiple non-overlapping multivariate patterns from hundreds of sequences effectively. Based on the mined results, we propose a glyph-based Sankey diagram to visualize the ever-changing tactic progression and support interactive data exploration. Through two case studies with four domain experts in tennis and badminton, we demonstrate that our system can effectively obtain insights about tactic progression in most racket sports. We further discuss the strengths and the limitations of our system based on domain expertsâ€™ feedback."
  },
  {
    "id": "Nebula",
    "title": "Nebula: A Coordinating Grammar of Graphics",
    "teaser": "source/projects/nebula/nebula.png",
    "authors": [
      "Ran Chen",
      "Xinhuan Shu",
      "Jiahui Chen",
      "Di Weng",
      "Junxiu Tang",
      "Siwei Fu",
      "Yingcai Wu"
    ],
    "source": "IEEE TVCG",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics",
    "year": 2021,
    "video": "https://youtu.be/oMgO0BVX8rY",
    "embedVideo": "https://www.youtube.com/embed/oMgO0BVX8rY",
    "abstract": "In multiple coordinated views (MCVs),visualizations across views update their content in response to users interactions in other views. Interactive systems provide direct manipulation to create coordination between views, but are restricted to limited types of predefined templates. By contrast, textual specification languages enable flexible coordination but expose technical burden. To bridge the gap, we contribute Nebula, a grammar based on natural language for coordinating visualizations in MCVs. The grammar design is informed by a novel framework based on a systematic review of 176 coordinations from existing theories and applications, which describes coordination by demonstration, i.e., how coordination is performed by users. With the framework, Nebula specification formalizes coordination as a composition of user- and coordination-triggered interactions in origin and destination views, respectively, along with potential data transformation between the interactions. We evaluate Nebula by demonstrating its expressiveness with a gallery of diverse examples and analyzing its usability on cognitive dimensions.",
    "paper": "source/projects/nebula/Nebula.pdf",
    "system": "https://nebula-vis.github.io/examples"
  },
  {
    "id": "Tac-Valuer",
    "title": "Tac-Valuer: Knowledge-based Stroke Evaluation in Table Tennis",
    "teaser": "source/projects/tacValuer/tacValuer.png",
    "authors": [
      "Jiachen Wang",
      "Dazhen Deng",
      "Xiao Xie",
      "Xinhuan Shu",
      "Yu-Xuan Huang",
      "Le-Wen Cai",
      "Hui Zhang",
      "Min-Ling Zhang",
      "Zhi-Hua Zhou",
      "Yingcai Wu"
    ],
    "source": "KDD",
    "transaction": "The ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2021)",
    "paper": "source/projects/tacValuer/tacValuer.pdf",
    "year": 2021,
    "abstract": "Stroke evaluation is critical for coaches to evaluate players' performance in table tennis matches. However, current methods highly demand proficient knowledge in table tennis and are time-consuming. We collaborate with the Chinese national table tennis team and propose Tac-Valuer, an automatic stroke evaluation framework for analysts in table tennis teams. In particular, to integrate analysts' knowledge into the machine learning model, we employ the latest effective framework named abductive learning, showing promising performance. Based on abductive learning, Tac-Valuer combines the state-of-the-art computer vision algorithms to extract and embed stroke features for evaluation. We evaluate the design choices of the approach and present Tac-Valuer's usability through use cases that analyze the performance of the top table tennis players in world-class events."
  },
  {
    "id": "CareerLens",
    "title": "Interactive Visual Exploration of Longitudinal Historical Career Mobility Data",
    "teaser": "source/projects/CareerLens/teaser.png",
    "authors": [
      "Yifang Wang",
      "Hongye Liang",
      "Xinhuan Shu",
      "Jiachen Wang",
      "Ke Xu",
      "Zikun Deng",
      "Cameron Campbell",
      "Bijia Chen",
      "Yingcai Wu",
      "Huamin Qu"
    ],
    "source": "IEEE TVCG",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics",
    "volume": 0,
    "issue": 0,
    "year": 2021,
    "video": "https://youtu.be/2IDCtCMpVZw",
    "embedVideo": "https://www.youtube.com/embed/2IDCtCMpVZw",
    "abstract": "The increased availability of quantitative historical datasets has provided new research opportunities for multiple disciplines in social science. In this paper, we work closely with the constructors of a new dataset, CGED-Q (China Government Employee Database-Qing), that records the career trajectories of over 340,000 government officials in the Qing bureaucracy in China from 1760 to 1912. We use these data to study career mobility from a historical perspective and understand social mobility and inequality. However, existing statistical approaches are inadequate for analyzing career mobility in this historical dataset with its fine-grained attributes and long time span, since they are mostly hypothesis-driven and require substantial effort. We propose CareerLens, an interactive visual analytics system for assisting experts in exploring, understanding, and reasoning from historical career data. With CareerLens, experts examine mobility patterns in three levels-of-detail, namely, the macro-level providing a summary of overall mobility, the meso-level extracting latent group mobility patterns, and the micro-level revealing social relationships of individuals. We demonstrate the effectiveness and usability of CareerLens through two case studies and receive encouraging feedback from follow-up interviews with domain experts.",
    "paper": "source/projects/CareerLens/CareerLens.pdf"
  },
  {
    "id": "VisCas",
    "title": "Visual Cascade Analytics of Large-scale Spatiotemporal Data",
    "teaser": "source/projects/VisCas/VisCas.png",
    "authors": [
      "Zikun Deng",
      "Di Weng",
      "Yuxuan Liang",
      "Jie Bao",
      "Yu Zheng",
      "Tobias Schreck",
      "Mingliang Xu",
      "Yingcai Wu"
    ],
    "source": "IEEE TVCG",
    "transaction": "IEEE Transaction on Visualization and Computer Graphics",
    "volume": 0,
    "issue": 1,
    "year": 2021,
    "video": "https://www.youtube.com/watch?v=IVSf0BNRC_c",
    "embedVideo": "https://www.youtube.com/embed/IVSf0BNRC_c",
    "abstract": "Many spatiotemporal events can be viewed as contagions. These events implicitly propagate across space and time by following cascading patterns, expanding their influence, and generating event cascades that involve multiple locations. Analyzing such cascading processes presents valuable implications in various urban applications, such as traffic planning and pollution diagnostics. Motivated by the limited capability of the existing approaches in mining and interpreting cascading patterns, we propose a visual analytics system called VisCas. VisCas combines an inference model with interactive visualizations and empowers analysts to infer and interpret the latent cascading patterns in the spatiotemporal context. To develop VisCas, we address three major challenges, 1) generalized pattern inference, 2) implicit influence visualization, and 3) multifaceted cascade analysis. For the first challenge, we adapt the state-of-the-art cascading network inference technique to general urban scenarios, where cascading patterns can be reliably inferred from large-scale spatiotemporal data. For the second and third challenges, we assemble a set of effective visualizations to support location navigation, influence inspection, and cascading exploration, and facilitate the in-depth cascade analysis. We design a novel influence view based on a three-fold optimization strategy for analyzing the implicit influences of the inferred patterns. We demonstrate the capability and effectiveness of VisCas with two case studies conducted on real-world traffic congestion and air pollution datasets with domain experts.",
    "paper": "source/projects/VisCas/VisCas.pdf"
  },
  {
    "id": "Tac-Miner",
    "title": "Tac-Miner: Visual Tactic Mining for Multiple Table Tennis Matches",
    "titleKey": [
      "Honorable Mention"
    ],
    "teaser": "source/projects/TacMiner/tacminer.png",
    "authors": [
      "Jiachen Wang",
      "Jiang Wu",
      "Anqi Cao",
      "Zheng Zhou",
      "Hui Zhang",
      "Yingcai Wu"
    ],
    "source": "PacificVis",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE Pacific Visualization 2021)",
    "volume": 0,
    "issue": 0,
    "year": 2021,
    "video": "https://youtu.be/MCv7BF2Njtk",
    "embedVideo": "https://www.youtube.com/embed/MCv7BF2Njtk",
    "abstract": "In table tennis, tactics specified by three consecutive strokes represent the high-level competition strategies in matches. Effective detection and analysis of tactics can reveal the playing styles of players, as well as their strengths and weaknesses. However, tactical analysis in table tennis is challenging as the analysts can often be overwhelmed by the large quantity and high dimension of the data. Statistical charts have been extensively used by researchers to explore and visualize table tennis data. However, these charts cannot support efficient comparative and correlation analysis of complicated tactic attributes. Besides, existing studies are limited to the analysis of one match. However, one player's strategy can change along with his/her opponents in different matches. Therefore, the data of multiple matches can support a more comprehensive tactical analysis. To address these issues, we introduced a visual analytics system called Tac-Miner to allow analysts to effectively analyze, explore, and compare tactics of multiple matches based on the advanced embedding and dimension reduction algorithms along with an interactive glyph. We evaluate our glyph's usability through a user study and demonstrate the system's usefulness through a case study with insights approved by coaches and domain experts.",
    "paper": "source/projects/TacMiner/tacminer.pdf"
  },
  {
    "id": "EventAnchor",
    "title": "EventAnchor: Reducing Human Interactions in Event Annotation of Racket Sports Videos",
    "teaser": "source/projects/eventanchor/eventanchor.png",
    "authors": [
      "Dazhen Deng",
      "Jiang Wu",
      "Jiachen Wang",
      "Yihong Wu",
      "Xiao Xie",
      "Zheng Zhou",
      "Hui Zhang",
      "Xiaolong Zhang",
      "Yingcai Wu"
    ],
    "source": "CHI",
    "transaction": "The ACM CHI Conference on Human Factors in Computing Systems (CHI 2021)",
    "year": 2021,
    "video": "https://youtu.be/TPpzko4TDWQ",
    "embedVideo": "https://www.youtube.com/embed/TPpzko4TDWQ",
    "abstract": "The popularity of racket sports (e.g., tennis and table tennis) leads to high demands for data analysis, such as notational analysis, on player performance. While sports videos offer many benefits for such analysis, retrieving accurate information from sports videos could be challenging. In this paper, we propose EventAnchor, a data analysis framework to facilitate interactive annotation of racket sports video with the support of computer vision algorithms. Our approach uses machine learning models in computer vision to help users acquire essential events from videos (e.g., serve, the ball bouncing on the court) and offers users a set of interactive tools for data annotation. An evaluation study on a table tennis annotation system built on this framework shows significant improvement of user performances in simple annotation tasks on objects of interest and complex annotation tasks requiring domain knowledge.",
    "paper": "source/projects/eventanchor/eventanchor.pdf"
  },
  {
    "id": "PlotThread",
    "title": "PlotThread: Creating Expressive Storyline Visualizations using Reinforcement Learning",
    "teaser": "source/projects/plotthread/plotthread.png",
    "authors": [
      "Tan Tang",
      "Renzhong Li",
      "Xinke Wu",
      "Shuhan Liu",
      "Johannes Knittel",
      "Steffen Koch",
      "Thomas Ertl",
      "Lingyun Yu",
      "Peiran Ren",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS (InfoVis)",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE InfoVis 2020)",
    "volume": 27,
    "issue": 1,
    "year": 2020,
    "video": "https://youtu.be/OZkAvNPHu7Y",
    "embedVideo": "https://www.youtube.com/embed/OZkAvNPHu7Y",
    "abstract": "Storyline visualizations are an effective means to present the evolution of plots and reveal the scenic interactions amongcharacters. However, the design of storyline visualizations is a difficult task as users need to balance between aesthetic goals andnarrative constraints. Despite that the optimization-based methods have been improved significantly in terms of producing aestheticand legible layouts, the existing (semi-) automatic methods are still limited regarding 1) efficient exploration of the storyline designspace and 2) flexible customization of storyline layouts. In this work, we propose a reinforcement learning framework to train an AIagent that assists users in exploring the design space efficiently and generating well-optimized storylines. Based on the framework, we introduce PlotThread, an authoring tool that integrates a set of flexible interactions to support easy customization of storylinevisualizations. To seamlessly integrate the AI agent into the authoring process, we employ a mixed-initiative approach where both theagent and designers work on the same canvas to boost the collaborative design of storylines. We evaluate the reinforcement learningmodel through qualitative and quantitative experiments and demonstrate the usage of PlotThread using a collection of use cases",
    "paper": "source/projects/plotthread/plotthread.pdf"
  },
  {
    "id": "BusNet",
    "title": "Towards Better Bus Networks: A Visual Analytics Approach",
    "teaser": "source/projects/busnet/busnet.png",
    "authors": [
      "Di Weng",
      "Chengbo Zheng",
      "Zikun Deng",
      "Mingze Ma",
      "Jie Bao",
      "Yu Zheng",
      "Mingliang Xu",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS (VAST)",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VAST 2020)",
    "volume": 27,
    "issue": 1,
    "year": 2020,
    "video": "https://youtu.be/vBSwbbPRd_g",
    "embedVideo": "https://www.youtube.com/embed/vBSwbbPRd_g",
    "abstract": "Bus routes are typically updated every 3â€“5 years to meet constantly changing travel demands. However, identifying deficientbus routes and finding their optimal replacements remain challenging due to the difficulties in analyzing a complex bus network and thelarge solution space comprising alternative routes. Most of the automated approaches cannot produce satisfactory results in real-worldsettings without laborious inspection and evaluation of the candidates. The limitations observed in these approaches motivate us tocollaborate with domain experts and propose a visual analytics solution for the performance analysis and incremental planning ofbus routes based on an existing bus network. Developing such a solution involves three major challenges, namely, a) the in-depthanalysis of complex bus route networks, b) the interactive generation of improved route candidates, and c) the effective evaluation ofalternative bus routes. For challenge a, we employ an overview-to-detail approach by dividing the analysis of a complex bus networkinto three levels to facilitate the efficient identification of deficient routes. For challenge b, we improve a route generation model andinterpret the performance of the generation with tailored visualizations. For challenge c, we incorporate a conflict resolution strategy inthe progressive decision-making process to assist users in evaluating the alternative routes and finding the most optimal one. Theproposed system is evaluated with two usage scenarios based on real-world data and received positive feedback from the experts.",
    "paper": "source/projects/busnet/busnet.pdf"
  },
  {
    "id": "PassVizor",
    "title": "PassVizor: Toward Better Understanding of the Dynamics of Soccer Passes",
    "teaser": "source/projects/passvizor/passvizor.png",
    "authors": [
      "Xiao Xie",
      "Jiachen Wang",
      "Hongye Liang",
      "Dazhen Deng",
      "Shoubin Cheng",
      "Hui Zhang",
      "Wei Chen",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS (VAST)",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VAST 2020)",
    "volume": 27,
    "issue": 1,
    "year": 2020,
    "video": "https://youtu.be/Lr6yuBBrMQw",
    "embedVideo": "https://www.youtube.com/embed/Lr6yuBBrMQw",
    "abstract": "In soccer, passing is the most frequent interaction between players and plays a significant role in creating scoring chances. Experts are interested in analyzing playersâ€™ passing behavior to learn passing tactics, i.e., how players build up an attack with passing. Various approaches have been proposed to facilitate the analysis of passing tactics. However, the dynamic changes of a teamâ€™semployed tactics over a match have not been comprehensively investigated. To address the problem, we closely collaborate withdomain experts and characterize requirements to analyze the dynamic changes of a teamâ€™s passing tactics. To characterize thepassing tactic employed for each attack, we propose a topic-based approach that provides a high-level abstraction of complex passingbehaviors. Based on the model, we propose a glyph-based design to reveal the multi-variate information of passing tactics withindifferent phases of attacks, including player identity, spatial context, and formation. We further design and develop PassVizor, a visualanalytics system, to support the comprehensive analysis of passing dynamics. With the system, users can detect the changing patternsof passing tactics and examine the detailed passing process for evaluating passing tactics. We invite experts to conduct analysis withPassVizor and demonstrate the usability of the system through an expert interview.",
    "paper": "source/projects/passvizor/passvizor.pdf"
  },
  {
    "id": "ShuttleSpace",
    "title": "ShuttleSpace: Exploring and Analyzing Movement Trajectory in Immersive Visualization",
    "teaser": "source/projects/shuttlespace/shuttlespace.png",
    "authors": [
      "Shuainan Ye",
      "Zhutian Chen",
      "Xiangtong Chu",
      "Yifan Wang",
      "Siwei Fu",
      "Lejun Shen",
      "Kun Zhou",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS (InfoVis)",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE InfoVis 2020)",
    "volume": 27,
    "issue": 1,
    "year": 2020,
    "video": "https://youtu.be/-yJi-4OleDk",
    "embedVideo": "https://www.youtube.com/embed/-yJi-4OleDk",
    "abstract": "We present ShuttleSpace, an immersive analytics system to assist experts in analyzing trajectory data in badminton. Trajectories in sports, such as the movement of players and balls, contain rich information on player behavior and thus have beenwidely analyzed by coaches and analysts to improve the playersâ€™ performance. However, existing visual analytics systems often presentthe trajectories in court diagrams that are abstractions of reality, thereby causing difficulty for the experts to imagine the situation on thecourt and understand why the player acted in a certain way. With recent developments in immersive technologies, such as virtual reality(VR), experts gradually have the opportunity to see, feel, explore, and understand these 3D trajectories from the playerâ€™s perspective. Yet, few research has studied how to support immersive analysis of sports data from such a perspective. Specific challenges are rootedin data presentation (e.g., how to seamlessly combine 2D and 3D visualizations) and interaction (e.g., how to naturally interact withdata without keyboard and mouse) in VR. To address these challenges, we have worked closely with domain experts who have workedfor a top national badminton team to design ShuttleSpace. Our system leverages 1) the peripheral vision to combine the 2D and 3Dvisualizations and 2) the VR controller to support natural interactions via a stroke metaphor. We demonstrate the effectiveness ofShuttleSpace through three case studies conducted by the experts with useful insights. We further conduct interviews with the expertswhose feedback confirms that our first-person immersive analytics system is suitable and useful for analyzing badminton data.",
    "paper": "source/projects/shuttlespace/shuttlespace.pdf"
  },
  {
    "id": "Fine-tuning Layout",
    "title": "Exemplar-based Layout Fine-tuning for Node-link Diagrams",
    "teaser": "source/projects/finetuninglayout/finetuninglayout.png",
    "authors": [
      "Jiacheng Pan",
      "Wei Chen",
      "Xiaodong Zhao",
      "Shuyue Zhou",
      "Wei Zeng",
      "Minfeng Zhu",
      "Jian Chen",
      "Siwei Fu",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS (InfoVis)",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE InfoVis 2020)",
    "volume": 27,
    "issue": 1,
    "year": 2020,
    "video": "http://www.cad.zju.edu.cn/home/vagblog/images/photo_bed/2020/8/19/29b5e20e480a3e49d58e60aeac01a005ab8f0d32.mp4",
    "embedVideo": "http://www.cad.zju.edu.cn/home/vagblog/images/photo_bed/2020/8/19/29b5e20e480a3e49d58e60aeac01a005ab8f0d32.mp4",
    "abstract": "We design and evaluate a novel layout fine-tuning technique for node-link diagrams that facilitates exemplar-based adjustment of a group of substructures in batching mode. The key idea is to transfer user modifications on a local substructure to other substructures in the whole graph that are topologically similar to the exemplar. We first precompute a canonical representation for each substructure with node embedding techniques and then use it for on-the-fly substructure retrieval. We design and develop a light-weight interactive system to enable intuitive adjustment, modification transfer, and visual graph exploration. We also report some results of quantitative comparisons, three case studies, and a within-participant user study.",
    "paper": "source/projects/finetuninglayout/finetuninglayout.pdf"
  },
  {
    "id": "CausalExplorer",
    "title": "A Visual Analytics Approach for Exploratory Causal Analysis: Exploration, Validation, and Applications",
    "teaser": "source/projects/CausalExplorer/CausalExplorer.png",
    "authors": [
      "Xiao Xie",
      "Fan Du",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS (VAST)",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VAST 2020)",
    "volume": 27,
    "issue": 1,
    "year": 2020,
    "abstract": "Using causal relations to guide decision making has become an essential analytical task across various domains, frommarketing and medicine to education and social science. While powerful statistical models have been developed for inferring causalrelations from data, domain practitioners still lack effective visual interface for interpreting the causal relations and applying them in theirdecision-making process. Through interview studies with domain experts, we characterize their current decision-making workflows,challenges, and needs. Through an iterative design process, we developed a visualization tool that allows analysts to explore, validate, and apply causal relations in real-world decision-making scenarios. The tool provides an uncertainty-aware causal graph visualizationfor presenting a large set of causal relations inferred from high-dimensional data. On top of the causal graph, it supports a set ofintuitive user controls for performing what-if analyses and making action plans. We report on two case studies in marketing and studentadvising to demonstrate that users can effectively explore causal relations and design action plans for reaching their goals.",
    "paper": "source/projects/CausalExplorer/CausalExplorer.pdf"
  },
  {
    "id": "Data-GIF",
    "title": "What Makes a Data-GIF Understandable?",
    "teaser": "source/projects/datagif/datagif.png",
    "authors": [
      "Xinhuan Shu",
      "Aoyu Wu",
      "Junxiu Tang",
      "Benjamin Bach",
      "Yingcai Wu",
      "Huamin Qu"
    ],
    "source": "IEEE VIS (InfoVis)",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE InfoVis 2020)",
    "volume": 27,
    "issue": 1,
    "year": 2020,
    "abstract": "GIFs are enjoying increasing popularity on social media as a format for data-driven storytelling with visualization; simplevisual messages are embedded in short animations that usually last less than 15 seconds and are played in automatic repetition. Inthis paper, we ask the question,â€œWhat makes a data-GIF understandable?â€While other storytelling formats such as data videos, infographics, or data comics are relatively well studied, we have little knowledge about the design factors and principles for â€œdata-GIFsâ€. To close this gap, we provide results from semi-structured interviews and an online study with a total of 118 participants investigating theimpact of design decisions on the understandability of data-GIFs. The study and our consequent analysis are informed by a systematicreview and structured design space of 108 data-GIFs that we found online. Our results show the impact of design dimensions from ourdesign space such as animation encoding, context preservation, or repetition on viewers understanding of the GIFâ€™s core message. The paper concludes with a list of suggestions for creating more effective Data-GIFs.",
    "paper": "source/projects/datagif/datagif.pdf",
    "video": "https://youtu.be/PFLrrK_4jj0",
    "embedVideo": "https://www.youtube.com/embed/PFLrrK_4jj0",
    "system": "https://data-gifs.github.io/"
  },
  {
    "id": "ESRac",
    "title": "Visual Analytics of Multivariate Event Sequence Data in Racquet Sports",
    "teaser": "source/projects/esrac/esrac.png",
    "authors": [
      "Jiang Wu",
      "Ziyang Guo",
      "Zuobin Wang",
      "Qingyang Xu",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS (VAST)",
    "transaction": "IEEE VAST 2020 (Conference Track)",
    "year": 2020,
    "abstract": "In this work, we propose a generic visual analytics framework tosupport tactic analysis based on data collected from racquet sports(such as tennis and badminton). The proposed approach models eachrally in a game as a sequence of hits (i.e., events) until one athletescores a point. Each hit can be described with a set of attributes, suchas the positions of the ball and the techniques used to hit the ball(such asdriveandvolleyin tennis). Thus, the mentioned sequence ofhits can be viewed as a multivariate event sequence. By detecting andanalyzing the multivariate subsequences that frequently occur in therallies (namely, tactical patterns), athletes can gain insights into theplaying styles adopted by their opponents, and therefore help themidentify systematic weaknesses of the opponents and develop counterstrategies in matches. To support such analysis effectively, wepropose a steerable multivariate sequential pattern mining algorithmwith adjustable weights over event attributes, such that the domainexpert can obtain frequent tactical patterns according to the attributesspecified by himself. We also propose a re-configurable glyph designto help users simultaneously analyze multiple attributes of the hits. The framework further supports comparative analysis of the tacticalpatterns, e.g., for different athletes or the same athlete playing underdifferent conditions. By applying the framework on two datasetscollected in tennis and badminton matches, we demonstrate thatthe system is generic and effective for tactic analysis in sports andcan help identify signature techniques used by individual athletes.Finally, we discuss the strengths and limitations of the proposedapproach based on the feedback from the domain experts.",
    "paper": "source/projects/esrac/esrac.pdf",
    "video": "https://youtu.be/wy1K0mWDFDg",
    "embedVideo": "https://www.youtube.com/embed/wy1K0mWDFDg"
  },
  {
    "id": "TransVideo",
    "title": "Narrative Transitions in Data Videos",
    "teaser": "source/projects/TransVideo/transVideo.png",
    "authors": [
      "Junxiu Tang",
      "Lingyun Yu",
      "Tan Tang",
      "Xinhuan Shu",
      "Lu Ying",
      "Yuhua Zhou",
      "Peiran Ren",
      "Yingcai Wu"
    ],
    "source": "VIS Short Paper",
    "transaction": "IEEE VIS 2020 Short Papers",
    "year": 2020,
    "abstract": "Transitions are widely used in data videos to seamlessly connect data-driven charts or connect visualizations and non-data-driven motion graphics. To inform the transition designs in data videos, we conduct a content analysis based on more than 3500 clips extracted from 284 data videos. We annotate visualization types and transition designs on these segments, and examine how these transitions help make connections between contexts. We propose a taxonomy of transitions in data videos, where two transition categories are defined in building fluent narratives by using visual variables.",
    "paper": "source/projects/TransVideo/transVideo.pdf",
    "video": "https://youtu.be/RNFCuR9DgMg",
    "embedVideo": "https://www.youtube.com/embed/RNFCuR9DgMg"
  },
  {
    "id": "CorVizor",
    "title": "Towards Better Detection and Analysis of Massive Spatiotemporal Co-Occurrence Patterns",
    "teaser": "source/projects/corvizor/corvizor.png",
    "DOI": "10.1109/TITS.2020.2983226",
    "authors": [
      "Yingcai Wu",
      "Di Weng",
      "Zikun Deng",
      "Jie Bao",
      "Mingliang Xu",
      "Zhangye Wang",
      "Yu Zheng",
      "Zhiyu Ding",
      "Wei Chen"
    ],
    "source": "TITS",
    "transaction": "IEEE Transactions on Intelligent Transportation Systems (TITS 2020)",
    "volume": 1,
    "issue": 1,
    "page": [
      1,
      16
    ],
    "year": 2020,
    "abstract": "With the rapid development of sensing technologies, massive spatiotemporal data have been acquired from the urban space with respect to different domains, such as transportation and environment. Numerous co-occurrence patterns (e.g., traffic speed < 10km/h, weather = foggy, and air quality = unhealthy) between the transportation data and other types of data can be obtained with given spatiotemporal constraints (e.g., within 3 kilometers and lasting for 2 hours) from these heterogeneous data sources. Such patterns present valuable implications for many urban applications, such as traffic management, pollution diagnosis, and transportation planning. However, extracting and understanding these patterns is beyond manual capability because of the scale, diversity, and heterogeneity of the data. To address this issue, a novel visual analytics system called CorVizor is proposed to identify and interpret these co-occurrence patterns. CorVizor comprises two major components. The first component is a co-occurrence mining framework involving three steps, namely, spatiotemporal indexing, co-occurring instance generation, and pattern mining. The second component is a visualization technique called CorView that implements a level-of-detail mechanism by integrating tailored visualizations to depict the extracted spatiotemporal co-occurrence patterns. The case studies and expert interviews are conducted to demonstrate the effectiveness of CorVizor.",
    "paper": "source/projects/corvizor/corvizor.PDF",
    "video": "https://youtu.be/0T0xe-rppSo",
    "embedVideo": "https://www.youtube.com/embed/0T0xe-rppSo",
    "system": null
  },
  {
    "id": "Route Planning",
    "title": "Pareto-Optimal Transit Route Planning with Multi-Objective Monte-Carlo Tree Search",
    "teaser": "source/projects/routePlanning/routePlanning.png",
    "DOI": "10.1109/TITS.2020.2964012",
    "authors": [
      "Di Weng",
      "Ran Chen",
      "Jianhui Zhang",
      "Jie Bao",
      "Yu Zheng",
      "Yingcai Wu"
    ],
    "source": "TITS",
    "transaction": "IEEE Transactions on Intelligent Transportation Systems (TITS 2020)",
    "volume": 1,
    "issue": 1,
    "page": [
      1,
      11
    ],
    "year": 2020,
    "video": "https://youtu.be/vBSwbbPRd_g",
    "embedVideo": "https://www.youtube.com/embed/vBSwbbPRd_g",
    "abstract": "Planning ideal transit routes in the complex urban environment can improve the performance and efficiency of public transportation systems effectively. However, finding such routes is computationally difficult due to the huge solution space constituted by billions of possible routes. Considering the limited scalability of exact search methods, heuristic search methods were proposed to boost the efficiency and incorporate flexible constraints. Nevertheless, the existing methods conceal multiple criteria in an objective, and thus evaluating the performance of the generated route becomes challenging due to the lack of comparable alternatives. Inspired by the prior study, we formulate the definition of pareto-optimal transit routes based on multiple criteria. However, extracting these routes remains challenging because: A) the sheer volume of possible transit routes; and B) the sparsity of pareto-optimal routes. We address these challenges by developing an efficient search framework: for challenge A, a random search method is developed based on Monte Carlo tree search where the unproductive solution subspaces are pruned progressively to reduce the search cost; and for challenge B, an estimation method is derived to guide the search process by assessing the value for each solution subspace. The superior effectiveness of our approach in approximating the pareto-optimal transit routes was demonstrated by the comprehensive evaluation based on the real-world data.",
    "paper": "source/projects/routePlanning/routePlanning.pdf",
    "system": null
  },
  {
    "id": "Resource Allocation",
    "title": "Dynamic Public Resource Allocation based on Human Mobility Prediction",
    "teaser": "source/projects/resourceAllocation/resourceAllocation.png",
    "DOI": "10.1145/3380986",
    "authors": [
      "Sijie Ruan",
      "Jie Bao",
      "Yuxuan Liang",
      "Ruiyuan Li",
      "Tianfu He",
      "Chuishi Meng",
      "Yanhua Li",
      "Yingcai Wu",
      "Yu Zheng"
    ],
    "source": "IMWUT",
    "transaction": "Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT 2020)",
    "volume": 4,
    "issue": 1,
    "articleNo": 25,
    "year": 2020,
    "abstract": "The objective of public resource allocation, e.g., the deployment of billboards, surveillance cameras, base stations, trash bins, is to serve more people. However, due to the dynamics of human mobility patterns, people are distributed unevenly on the spatial and temporal domains. As a result, in many cases, redundant resources have to be deployed to meet the crowd coverage requirements, which leads to high deployment costs and low usage. Fortunately, with the development of unmanned vehicles, the dynamic allocation of those public resources becomes possible. To this end, we provide the first attempt to design an effective and efficient scheduling algorithm for the dynamic public resource allocation. We formulate the problem as a novel multi-agent long-term maximal coverage scheduling (MALMCS) problem, which considers the crowd coverage and the energy limitation during a whole day. Two main components are employed in the system: 1) multi-step crowd flow prediction, which makes multi-step crowd flow prediction given the current crowd flows and external factors; and 2) energy adaptive scheduling, which employs a two-step heuristic algorithm, i.e., energy adaptive scheduling (EADS), to generate a scheduling plan that maximizes the crowd coverage within the service time for agents. Extensive experiments based on real crowd flow data in Happy Valley (a popular theme park in Beijing) demonstrate the effectiveness and efficiency of our approach.",
    "paper": "source/projects/resourceAllocation/resourceAllocation.pdf",
    "system": null
  },
  {
    "id": "Efficient Path Query",
    "title": "Efficient Path Query Processing over Massive Trajectories on the Cloud",
    "teaser": "source/projects/efficientquery/efficientquery.png",
    "DOI": "10.1109/TBDATA.2018.2868936",
    "authors": [
      "Ruiyuan Li",
      "Sijie Ruan",
      "Jie Bao",
      "Yanhua Li",
      "Yingcai Wu",
      "Liang Hong",
      "Yu Zheng"
    ],
    "source": "TBD",
    "transaction": "IEEE Transactions on Big Data (TBD 2020)",
    "volume": 6,
    "issue": 1,
    "page": [
      66,
      79
    ],
    "year": 2020,
    "abstract": "A path query aims to find trajectories passing a given sequence of connected road segments within a time period. It is very useful in many urban applications: 1) traffic modeling, 2) frequent path mining, 3) intersection coordination, and 4) traffic anomaly detection. Existing solutions for path query processing are implemented based on single machines, which are not efficient for the following tasks: 1) indexing large-scale historical data; 2) handling real-time trajectory updates; and 3) processing concurrent path queries from urban data mining applications. In this paper, we design and implement a cloud-based path query processing framework based on Microsoft Azure. We modify existing suffix tree structure to index trajectories using Azure Table. The proposed system consists of two main parts: 1) back-end processing, which performs pre-processing (i.e., parsing and map-matching) and index building tasks with a distributed computing platform (i.e., Storm) used to efficiently handle massive real-time trajectory updates; and 2) query processing, which answers path queries using Azure Storm to improve efficiency and overcome I/O bottleneck. Extensive experiments are performed based on the real-time taxi trajectories from Guiyang City, the capital of Guizhou Province, China to confirm the system efficiency. We also demonstrate a real deployed traffic analysis system based on our query processing framework.",
    "paper": "source/projects/efficientquery/efficientquery.pdf",
    "video": "https://youtu.be/SASgQnGGj50",
    "embedVideo": "https://www.youtube.com/embed/SASgQnGGj50",
    "system": null
  },
  {
    "id": "Three Geo-based Features",
    "title": "A User Study on the Capability of Three Geo-based Features in Analyzing and Locating Trajectories",
    "teaser": "source/projects/threeGeo/threeGeo.png",
    "DOI": "10.1109/TITS.2018.2875021",
    "authors": [
      "Xumeng Wang",
      "Tianlong Gu",
      "Xiaonan Luo",
      "Xiwen Cai",
      "Tianyi Lao",
      "Wenlong Chen",
      "Yingcai Wu",
      "Jinhui Yu",
      "Wei Chen"
    ],
    "source": "TITS",
    "transaction": "IEEE Transactions on Intelligent Transportation Systems (TITS 2019)",
    "volume": 20,
    "issue": 9,
    "page": [
      3375,
      3385
    ],
    "year": 2019,
    "abstract": "Visual analysis is widely applied to study human mobility due to the ability of integrating contextual information from multiple data sources. Analyzing trajectory data through visualization improves the efficiency and accuracy of the analysis, yet it may induce exposure of the location privacy. To balance the location privacy and analysis effectiveness, this work focuses on the behaviors of different geo-based contexts in the process of trajectory interpretation. Three types of geo-based contexts are identified after surveying 94 related literatures. We further conduct experiments to investigate their capability by evaluating how they benefit the analysis, and whether they lead to location privacy exposure. Finally, we report and discuss interesting findings, and provide guidelines to the design of privacy-preserving analysis approaches for human periodic trajectories.",
    "paper": "source/projects/threeGeo/threeGeo.pdf",
    "system": null
  },
  {
    "id": "AirVis",
    "title": "AirVis: Visual Analytics of Air Pollution Propagation",
    "teaser": "source/projects/airvis/teaser.png",
    "DOI": "10.1109/TVCG.2019.2934670",
    "authors": [
      "Zikun Deng",
      "Di Weng",
      "Jiahui Chen",
      "Ren Liu",
      "Zhibin Wang",
      "Jie Bao",
      "Yu Zheng",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS (VAST)",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VAST 2019)",
    "volume": 26,
    "issue": 1,
    "page": [
      800,
      810
    ],
    "year": 2019,
    "abstract": "Air pollution has become a serious public health problem for many cities around the world. To find the causes of air pollution, the propagation processes of air pollutants must be studied at a large spatial scale. However, the complex and dynamic wind fields lead to highly uncertain pollutant transportation. The state-of-the-art data mining approaches cannot fully support the extensive analysis of such uncertain spatiotemporal propagation processes across multiple districts without the integration of domain knowledge. The limitation of these automated approaches motivates us to design and develop AirVis, a novel visual analytics system that assists domain experts in efficiently capturing and interpreting the uncertain propagation patterns of air pollution based on graph visualizations. Designing such a system poses three challenges: a) the extraction of propagation patterns; b) the scalability of pattern presentations; and c) the analysis of propagation processes. To address these challenges, we develop a novel pattern mining framework to model pollutant transportation and extract frequent propagation patterns efficiently from large-scale atmospheric data. Furthermore, we organize the extracted patterns hierarchically based on the minimum description length (MDL) principle and empower expert users to explore and analyze these patterns effectively on the basis of pattern topologies. We demonstrated the effectiveness of our approach through two case studies conducted with a real-world dataset and positive feedback from domain experts.",
    "paper": "source/projects/airvis/AirVis.pdf",
    "video": "https://youtu.be/XDehEF7dxu0",
    "embedVideo": "https://www.youtube.com/embed/orjRmmGVT-4",
    "system": null
  },
  {
    "id": "Tac-Simur",
    "title": "Tac-Simur: Tactic-based Simulative Visual Analytics of Table Tennis",
    "teaser": "source/projects/tacSimur/Tac-Simur.png",
    "DOI": "10.1109/TVCG.2019.2934630",
    "authors": [
      "Jiachen Wang",
      "Kejian Zhao",
      "Dazhen Deng",
      "Anqi Cao",
      "Xiao Xie",
      "Zheng Zhou",
      "Hui Zhang",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS (VAST)",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VAST 2019)",
    "volume": 26,
    "issue": 1,
    "page": [
      407,
      417
    ],
    "year": 2019,
    "abstract": "Simulative analysis in competitive sports can provide prospective insights, which can help improve the performance of players in future matches. However, adequately simulating the complex competition process and effectively explaining the simulation result to domain experts are typically challenging. This work presents a design study to address these challenges in table tennis. We propose a well-established hybrid second-order Markov chain model to characterize and simulate the competition process in table tennis. Compared with existing methods, our approach is the first to support the effective simulation of tactics, which represent high-level competition strategies in table tennis. Furthermore, we introduce a visual analytics system called Tac-Simur based on the proposed model for simulative visual analytics. Tac-Simur enables users to easily navigate different players and their tactics based on their respective performance in matches to identify the player and the tactics of interest for further analysis. Then, users can utilize the system to interactively explore diverse simulation tasks and visually explain the simulation results. The effectiveness and usefulness of this work are demonstrated by two case studies, in which domain experts utilize Tac-Simur to find interesting and valuable insights. The domain experts also provide positive feedback on the usability of Tac-Simur. Our work can be extended to other similar sports such as tennis and badminton.",
    "paper": "source/projects/tacSimur/Tac-Simur.pdf",
    "video": "https://youtu.be/_I6cne3Wd4U",
    "embedVideo": "https://youtube.com/embed/_I6cne3Wd4U"
  },
  {
    "id": "VA in MMORPGs",
    "title": "Visual Analytics of Dynamic Interplay Between Behaviors in MMORPGs",
    "teaser": "source/projects/bexplorer/bexplorer.png",
    "authors": [
      "Junhua Lu",
      "Xiao Xie",
      "Ji Lan",
      "Tai-Quan Peng",
      "Wei Chen",
      "Yingcai Wu"
    ],
    "source": "PacificVis",
    "transaction": "Proceedings of IEEE Paciï¬c Visualization Symposium (PacificVis 2019)",
    "volume": 0,
    "issue": 0,
    "page": [
      112,
      121
    ],
    "year": 2019,
    "abstract": "With the rapid development of massively multiplayer online role-playing games (MMORPGs), a huge amount of fine-grained data on the in-game activities of players have been recorded by MMORPGs operators. These data provide considerable opportunities with which to study the dynamic interplay between player behaviors and investigate the roles of various social structures that underlie such interplay. However, it is challenging to model and visualize these behavioral data. This study proposes a novel influence-susceptible model to measure the dynamic interplay between behaviors. Based on this model, we introduce a new visual analytics system called BeXplorer. This system enables analysts to interactively explore the dynamic interplay between player purchase and communication behaviors and to examine the manner in which this interplay is bound by social structures where players are embedded. Three case studies and a task-based evaluation are conducted to demonstrate the effectiveness and applicability of our method.",
    "paper": "source/projects/bexplorer/bexplorer-pvis2019.pdf",
    "video": "https://youtu.be/rF45T48L--8",
    "embedVideo": "https://www.youtube.com/embed/rF45T48L--8",
    "DOI": "10.1109/PacificVis.2019.00021"
  },
  {
    "id": "MARVisT",
    "title": "MARVisT: Authoring Glyph-based Visualization in Mobile Augmented Reality",
    "teaser": "source/projects/MarVisT/MarVisT.png",
    "authors": [
      "Zhutian Chen",
      "Yijia Su",
      "Yifang Wang",
      "Qianwen Wang",
      "Huamin Qu",
      "Yingcai Wu"
    ],
    "source": "IEEE TVCG",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics",
    "volume": 0,
    "issue": 0,
    "page": [
      1,
      1
    ],
    "year": 2019,
    "abstract": "Recent advances in mobile augmented reality (AR) techniques have shed new light on personal visualization for their advantages of fitting visualization within personal routines, situating visualization in a real-world context, and arousing users' interests. However, enabling non-experts to create data visualization in mobile AR environments is challenging given the lack of tools that allow in-situ design while supporting the binding of data to AR content. Most existing AR authoring tools require working on personal computers or manually creating each virtual object and modifying its visual attributes. We systematically study this issue by identifying the specificity of AR glyph-based visualization authoring tool and distill four design considerations. Following these design considerations, we design and implement MARVisT, a mobile authoring tool that leverages information from reality to assist non-experts in addressing relationships between data and virtual glyphs, real objects and virtual glyphs, and real objects and data. With MARVisT, users without visualization expertise can bind data to real-world objects to create expressive AR glyph-based visualizations rapidly and effortlessly, reshaping the representation of the real world with data. We use several examples to demonstrate the expressiveness of MARVisT. A user study with non-experts is also conducted to evaluate the authoring experience of MARVisT.",
    "paper": "source/projects/MarVisT/MarVisT.pdf",
    "video": "https://youtu.be/cbtbJXwpwdk",
    "embedVideo": "https://www.youtube.com/embed/cbtbJXwpwdk",
    "DOI": "10.1109/TVCG.2019.2892415"
  },
  {
    "id": "ForVizor",
    "title": "ForVizor: Visualizing Spatio-Temporal Team Formations in Soccer",
    "teaser": "source/projects/forvizor/forvizor.png",
    "authors": [
      "Yingcai Wu",
      "Xiao Xie",
      "Jiachen Wang",
      "Dazhen Deng",
      "Hongye Liang",
      "Hui Zhang",
      "Shoubin Cheng",
      "Wei Chen"
    ],
    "source": "IEEE VIS (VAST)",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE VAST 2018)",
    "volume": 25,
    "issue": 1,
    "page": [
      65,
      75
    ],
    "year": 2018,
    "abstract": "Regarded as a high-level tactic in soccer, a team formation assigns players different tasks and indicates their active regions on the pitch, thereby influencing the team performance significantly. Analysis of formations in soccer has become particularly indispensable for soccer analysts. However, formations of a team are intrinsically time-varying and contain inherent spatial information. The spatio-temporal nature of formations and other characteristics of soccer data, such as multivariate features, make analysis of formations in soccer a challenging problem. In this study, we closely worked with domain experts to characterize domain problems of formation analysis in soccer and formulated several design goals. We design a novel spatio-temporal visual representation of changes in team formation, allowing analysts to visually analyze the evolution of formations and track the spatial flow of players within formations over time. Based on the new design, we further design and develop ForVizor, a visual analytics system, which empowers users to track the spatio-temporal changes in formation and understand how and why such changes occur. With ForVizor, domain experts conduct formation analysis of two games. Analysis results with insights and useful feedback are summarized in two case studies.",
    "paper": "source/projects/forvizor/forvizor.pdf",
    "video": "https://www.youtube.com/watch?v=03U7PESGkOQ",
    "embedVideo": "https://www.youtube.com/embed/03U7PESGkOQ",
    "DOI": "10.1109/TVCG.2018.2865041"
  },
  {
    "id": "SRVis",
    "title": "SRVis: Towards Better Spatial Integration in Ranking Visualization",
    "teaser": "source/projects/srvis/srvis.png",
    "authors": [
      "Di Weng",
      "Ran Chen",
      "Zikun Deng",
      "Feiran Wu",
      "Jingmin Chen",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS (InfoVis)",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE InfoVis 2018)",
    "volume": 25,
    "issue": 1,
    "page": [
      459,
      469
    ],
    "year": 2018,
    "abstract": "Interactive ranking techniques have substantially promoted analysts' ability in making judicious and informed decisions effectively based on multiple criteria. However, the existing techniques cannot satisfactorily support the analysis tasks involved in ranking large-scale spatial alternatives, such as selecting optimal locations for chain stores, where the complex spatial contexts involved are essential to the decision-making process. Limitations observed in the prior attempts of integrating rankings with spatial contexts motivate us to develop a context-integrated visual ranking technique. Based on a set of generic design requirements we summarized by collaborating with domain experts, we propose SRVis, a novel spatial ranking visualization technique that supports efficient spatial multi-criteria decision-making processes by addressing three major challenges in the aforementioned context integration, namely, a) the presentation of spatial rankings and contexts, b) the scalability of rankings' visual representations, and c) the analysis of context-integrated spatial rankings. Specifically, we encode massive rankings and their cause with scalable matrix-based visualizations and stacked bar charts based on a novel two-phase optimization framework that minimizes the information loss, and the flexible spatial filtering and intuitive comparative analysis are adopted to enable the in-depth evaluation of the rankings and assist users in selecting the best spatial alternative. The effectiveness of the proposed technique has been evaluated and demonstrated with an empirical study of optimization methods, two case studies, and expert interviews.",
    "paper": "source/projects/srvis/srvis.pdf",
    "video": "https://www.youtube.com/watch?v=lenSZci4gy4",
    "embedVideo": "https://www.youtube.com/embed/lenSZci4gy4",
    "DOI": "10.1109/TVCG.2018.2865126"
  },
  {
    "id": "iStoryline",
    "title": "iStoryline: Effective Convergence to Hand-drawn Storylines",
    "teaser": "source/projects/istoryline/istoryline.png",
    "authors": [
      "Tan Tang",
      "Sadia Rubab",
      "Jiewen Lai",
      "Weiwei Cui",
      "Lingyun Yu",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS (InfoVis)",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (IEEE InfoVis 2018)",
    "volume": 25,
    "issue": 1,
    "page": [
      769,
      778
    ],
    "year": 2018,
    "abstract": "Storyline visualization techniques have progressed significantly to generate illustrations of complex stories automatically. However, the visual layouts of storylines are not enhanced accordingly despite the improvement in the performance and extension of its application area. Existing methods attempt to achieve several shared optimization goals, such as reducing empty space and minimizing line crossings and wiggles. However, these goals do not always produce optimal results when compared to hand-drawn storylines. We conducted a preliminary study to learn how users translate a narrative into a hand-drawn storyline and check whether the visual elements in hand-drawn illustrations can be mapped back to appropriate narrative contexts. We also compared the hand-drawn storylines with storylines generated by the state-of-the-art methods and found they have significant differences. Our findings led to a design space that summarizes (1) how artists utilize narrative elements and (2) the sequence of actions artists follow to portray expressive and attractive storylines. We developed iStoryline, an authoring tool for integrating high-level user interactions into optimization algorithms and achieving a balance between hand-drawn storylines and automatic layouts. iStoryline allows users to create novel storyline visualizations easily according to their preferences by modifying the automatically generated layouts. The effectiveness and usability of iStoryline are studied with qualitative evaluations.",
    "paper": "source/projects/istoryline/istoryline.pdf",
    "video": "https://www.youtube.com/watch?v=on4KbLd2RiY",
    "embedVideo": "https://www.youtube.com/embed/on4KbLd2RiY",
    "DOI": "10.1109/TVCG.2018.2864899"
  },
  {
    "id": "ImgVis",
    "title": "A Semantic-based Method for Visualizing Large Image Collections",
    "teaser": "source/projects/imagevis/imagevis.jpg",
    "authors": [
      "Xiao Xie",
      "Xiwen Cai",
      "Junpei Zhou",
      "Nan Cao",
      "Yingcai Wu"
    ],
    "source": "IEEE TVCG",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics",
    "volume": 25,
    "issue": 7,
    "page": [
      2362,
      2377
    ],
    "year": 2018,
    "abstract": "Interactive visualization of large image collections is important and useful in many applications, such as personal album management and user profiling on images. However, most prior studies focus on using low-level visual features of images, such as texture and color histogram, to create visualizations without considering the more important semantic information embedded in images. This paper proposes a novel visual analytic system to analyze images in a semantic-aware manner. The system mainly comprises two components: a semantic information extractor and a visual layout generator. The semantic information extractor employs an image captioning technique based on convolutional neural network (CNN) to produce descriptive captions for images, which can be transformed into semantic keywords. The layout generator employs a novel co-embedding model to project images and the associated semantic keywords to the same 2D space. Inspired by the galaxy metaphor, we further turn the projected 2D space to a galaxy visualization of images, in which semantic keywords and images are visually encoded as stars and planets. Our system naturally supports multi-scale visualization and navigation, in which users can immediately see a semantic overview of an image collection and drill down for detailed inspection of a certain group of images. Users can iteratively refine the visual layout by integrating their domain knowledge into the co-embedding process. Two task-based evaluations are conducted to demonstrate the effectiveness of our system.",
    "paper": "source/projects/imagevis/imgvis.pdf",
    "video": "https://www.youtube.com/watch?v=dOhs3YZBZTM",
    "embedVideo": "https://www.youtube.com/embed/dOhs3YZBZTM",
    "DOI": "10.1109/TVCG.2018.2835485"
  },
  {
    "id": "StreamExplorer",
    "title": "StreamExplorer: A Multi-Stage System for Visually Exploring Events in Social Streams",
    "teaser": "source/projects/streamexplorer/streamexplorer.png",
    "authors": [
      "Yingcai Wu",
      "Zhutian Chen",
      "Guodao Sun",
      "Xiao Xie",
      "Nan Cao",
      "Shixia Liu",
      "Weiwei Cui"
    ],
    "source": "IEEE TVCG",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics",
    "volume": 24,
    "issue": 10,
    "page": [
      2758,
      2772
    ],
    "year": 2018,
    "abstract": "Analyzing social streams is important for many applications, such as crisis management. However, the considerable diversity, increasing volume, and high dynamics of social streams of large events continue to be significant challenges that must be overcome to ensure effective exploration. We propose a novel framework by which to handle complex social streams on a budget PC. This framework features two components: 1) an online method to detect important time periods (i.e., subevents), and 2) a tailored GPU-assisted Self-Organizing Map (SOM) method, which clusters the tweets of subevents stably and efficiently. Based on the framework, we present StreamExplorer to facilitate the visual analysis, tracking, and comparison of a social stream at three levels. At a macroscopic level, StreamExplorer uses a new glyph-based timeline visualization, which presents a quick multi-faceted overview of the ebb and flow of a social stream. At a mesoscopic level, a map visualization is employed to visually summarize the social stream from either a topical or geographical aspect. At a microscopic level, users can employ interactive lenses to visually examine and explore the social stream from different perspectives. Two case studies and a task-based evaluation are used to demonstrate the effectiveness and usefulness of StreamExplorer.",
    "paper": "source/projects/streamexplorer/streamexplorer.pdf",
    "video": "https://www.youtube.com/watch?v=CReWsrgMGI4",
    "embedVideo": "https://www.youtube.com/embed/CReWsrgMGI4",
    "DOI": "10.1109/TVCG.2017.2764459"
  },
  {
    "id": "AbstractScatterplot",
    "title": "Cluster-based Visual Abstraction for Multivariate Scatterplots",
    "teaser": "source/projects/AbstractScatterplot/AbstractScatterplot.png",
    "authors": [
      "Hongsen Liao",
      "Yingcai Wu",
      "Li Chen",
      "Wei Chen"
    ],
    "source": "IEEE TVCG",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics",
    "volume": 24,
    "issue": 9,
    "page": [
      2531,
      2545
    ],
    "year": 2018,
    "abstract": "The use of scatterplots is an important method for multivariate data visualization. The point distribution on the scatterplot, along with variable values represented by each point, can help analyze underlying patterns in data. However, determining the multivariate data variation on a scatterplot generated using projection methods, such as multidimensional scaling, is difficult. Furthermore, the point distribution becomes unclear when the data scale is large and clutter problems occur. These conditions can significantly decrease the usability of scatterplots on multivariate data analysis. In this study, we present a cluster-based visual abstraction method to enhance the visualization of multivariate scatterplots. Our method leverages an adapted multilabel clustering method to provide abstractions of high quality for scatterplots. An image-based method is used to deal with large scale data problem. Furthermore, a suite of glyphs is designed to visualize the data at different levels of detail and support data exploration. The view coordination between the glyph-based visualization and the table lens can effectively enhance the multivariate data analysis. Through numerical evaluations for data abstraction quality, case studies and a user study, we demonstrate the effectiveness and usability of the proposed techniques for multivariate data analysis on scatterplots.",
    "paper": "source/projects/AbstractScatterplot/AbstractScatterplot.pdf",
    "DOI": "10.1109/TVCG.2017.2754480"
  },
  {
    "id": "iTTVis",
    "title": "iTTVis: Interactive Visualization of Table Tennis Data",
    "teaser": "source/projects/iTTVis/iTTVis.jpg",
    "authors": [
      "Yingcai Wu",
      "Ji Lan",
      "Xinhuan Shu",
      "Chenyang Ji",
      "Kejian Zhao",
      "Jiachen Wang",
      "Hui Zhang"
    ],
    "source": "IEEE VIS (InfoVis)",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (InfoVis 2017)",
    "volume": 24,
    "issue": 1,
    "page": [
      709,
      718
    ],
    "year": 2018,
    "abstract": "The rapid development of information technology paved the way for the recording of fine-grained data, such as stroke techniques and stroke placements, during a table tennis match. This data recording creates opportunities to analyze and evaluate matches from new perspectives. Nevertheless, the increasingly complex data poses a significant challenge to make sense of and gain insights into. Analysts usually employ tedious and cumbersome methods which are limited to watching videos and reading statistical tables. However, existing sports visualization methods cannot be applied to visualizing table tennis competitions due to different competition rules and particular data attributes. In this work, we collaborate with data analysts to understand and characterize the sophisticated domain problem of analysis of table tennis data. We propose iTTVis, a novel interactive table tennis visualization system, which to our knowledge, is the first visual analysis system for analyzing and exploring table tennis data. iTTVis provides a holistic visualization of an entire match from three main perspectives, namely, time-oriented, statistical, and tactical analyses. The proposed system with several well-coordinated views not only supports correlation identification through statistics and pattern detection of tactics with a score timeline but also allows cross analysis to gain insights. Data analysts have obtained several new insights by using iTTVis. The effectiveness and usability of the proposed system are demonstrated with four case studies.",
    "paper": "source/projects/iTTVis/iTTVis.pdf",
    "video": "https://www.youtube.com/watch?v=yuninyIr2dQ",
    "embedVideo": "https://www.youtube.com/embed/yuninyIr2dQ",
    "DOI": "10.1109/TVCG.2017.2744218"
  },
  {
    "id": "ViewpointSelection",
    "title": "Similarity Voting based Viewpoint Selection for Volumes",
    "teaser": "source/projects/ViewpointSelection/ViewpointSelection.jpeg",
    "authors": [
      "Yubo Tao",
      "Qirui Wang",
      "Wei Chen",
      "Yingcai Wu",
      "Hai Lin"
    ],
    "source": "EuroVis",
    "transaction": "Computer Graphics Forum (EuroVis 2016)",
    "volume": 35,
    "issue": 3,
    "page": [
      391,
      400
    ],
    "year": 2016,
    "abstract": "Previous viewpoint selection methods in volume visualization are generally based on some deterministic measures of viewpoint quality. However, they may not express the familiarity and aesthetic sense of users for features of interest. In this paper, we propose an image-based viewpoint selection model to learn how visualization experts choose representative viewpoints for volumes with similar features. For a given volume, we first collect images with similar features, and these images reflect the viewpoint preferences of the experts when visualizing these features. Each collected image tallies votes to the viewpoints with the best matching based on an image similarity measure, which evaluates the spatial shape and appearance similarity between the collected image and the rendered image from the viewpoint. The optimal viewpoint is the one with the most votes from the collected images, that is, the viewpoint chosen by most visualization experts for similar features. We performed experiments on various volumes available in volume visualization, and made comparisons with traditional viewpoint selection methods. The results demonstrate that our model can select more canonical viewpoints, which are consistent with human perception.",
    "paper": "source/projects/ViewpointSelection/ViewpointSelection.pdf",
    "DOI": "10.1111/cgf.12915"
  },
  {
    "id": "SocialMediaSurvey",
    "title": "A Survey on Visual Analytics of Social Media Data",
    "teaser": "source/projects/SocialMediaSurvey/SocialMediaSurvey.png",
    "authors": [
      "Yingcai Wu",
      "Nan Cao",
      "David Gotz",
      "Yap-Peng Tan",
      "Daniel A. Keim"
    ],
    "source": "TMM",
    "transaction": "IEEE Transactions on Multimedia",
    "volume": 18,
    "issue": 11,
    "page": [
      2135,
      2148
    ],
    "year": 2016,
    "abstract": "The unprecedented availability of social media data offers substantial opportunities for data owners, system operators, solution providers, and end users to explore and understand social dynamics. However, the exponential growth in the volume, velocity, and variability of social media data prevents people from fully utilizing such data. Visual analytics, which is an emerging research direction, has received considerable attention in recent years. Many visual analytics methods have been proposed across disciplines to understand large-scale structured and unstructured social media data. This objective, however, also poses significant challenges for researchers to obtain a comprehensive picture of the area, understand research challenges, and develop new techniques. In this paper, we present a comprehensive survey to characterize this fast-growing area and summarize the state-of-the-art techniques for analyzing social media data. In particular, we classify existing techniques into two categories: gathering information and understanding user behaviors. We aim to provide a clear overview of the research area through the established taxonomy. We then explore the design space and identify the research trends. Finally, we discuss challenges and open questions for future studies.",
    "paper": "source/projects/SocialMediaSurvey/SocialMediaSurvey.pdf",
    "DOI": "10.1109/TMM.2016.2614220"
  },
  {
    "id": "K-Location",
    "title": "Mining the Most Influential k-Location Set from Massive Trajectories",
    "teaser": "source/projects/K-Location/K-Location.png",
    "authors": [
      "Yuhong Li",
      "Jie Bao",
      "Yanhua Li",
      "Yingcai Wu",
      "Zhiguo Gong",
      "Yu Zheng"
    ],
    "source": "SIGSPATIAL",
    "transaction": "IEEE Transactions on Big Data (SIGSPATIAL 2016)",
    "volume": 4,
    "issue": 4,
    "page": [
      556,
      570
    ],
    "year": 2017,
    "abstract": "Mining the most influential location set finds k locations, traversed by the maximum number of unique trajectories, in a given spatial region. These influential locations are valuable for resource allocation applications, such as selecting charging stations for electric automobiles and suggesting locations for placing billboards. This problem is NP-hard and usually calls for an interactive mining processes involving a user's input, e.g., changing the spatial region and k, or removing some locations (from the results in the previous round) that are not eligible for an application according to the domain knowledge. Efficiency is the major concern in conducting this human-in-the-loop mining. To this end, we propose a complete mining framework, which includes an optimal method for the light setting (i.e., small region and k) and an approximate method for the heavy setting (i.e., large region and k). The optimal method leverages vertex grouping and best-first pruning techniques to expedite the mining process. The approximate method can provide the performance guarantee by utilizing the greedy heuristic, and it is comprised of efficient updating strategy, index partition and workload-based optimization techniques. We evaluate the efficiency and effectiveness of our methods based on two taxi datasets from China, and one check-in dataset from New York.",
    "paper": "source/projects/K-Location/K-Location.pdf",
    "DOI": "10.1109/TBDATA.2017.2717978"
  },
  {
    "id": "Doughnut",
    "title": "A Study of the Effect of Doughnut Chart Parameters on Proportion Estimation Accuracy",
    "teaser": "source/projects/doughnut/doughnut.jpg",
    "authors": [
      "Xiwen Cai",
      "Konstantinos Efstathiou",
      "Xiao Xie",
      "Yingcai Wu",
      "Yan Shi",
      "Lingyun Yu"
    ],
    "source": "EuroVis",
    "transaction": "Computer Graphics Forum (EuroVis 2018)",
    "volume": 37,
    "issue": 6,
    "page": [
      300,
      312
    ],
    "year": 2018,
    "abstract": "Pie and doughnut charts nicely convey the partâ€“whole relationship and they have become the most recognizable chart types for representing proportions in business and data statistics. Many experiments have been carried out to study human perception of the pie chart, while the corresponding aspects of the doughnut chart have seldom been tested, even though the doughnut chart and the pie chart share several similarities. In this paper, we report on a series of experiments in which we explored the effect of a few fundamental design parameters of doughnut charts, and additional visual cues, on the accuracy of such charts for proportion estimates. Since mobile devices are becoming the primary devices for casual reading, we performed all our experiments on such device. Moreover, the screen size of mobile devices is limited and it is therefore important to know how such size constraint affects the proportion accuracy. For this reason, in our first experiment we tested the chart size and we found that it has no significant effect on proportion accuracy. In our second experiment, we focused on the effect of the doughnut chart inner radius and we found that the proportion accuracy is insensitive to the inner radius, except the case of the thinnest doughnut chart. In the third experiment, we studied the effect of visual cues and found that marking the centre of the doughnut chart or adding tick marks at 25% intervals improves the proportion accuracy. Based on the results of the three experiments, we discuss the design of doughnut charts and offer suggestions for improving the accuracy of proportion estimates.",
    "paper": "source/projects/doughnut/donutchart.pdf",
    "DOI": "10.1111/cgf.13325"
  },
  {
    "id": "HomeFinder",
    "title": "HomeFinder Revisited: Finding Ideal Homes with Reachability-Centric Multi-Criteria Decision Making",
    "teaser": "source/projects/homefinder/reach.png",
    "authors": [
      "Di Weng",
      "Heming Zhu",
      "Jie Bao",
      "Yu Zheng",
      "Yingcai Wu"
    ],
    "source": "CHI",
    "transaction": "The ACM CHI Conference on Human Factors in Computing Systems (CHI 2018)",
    "page": [
      1,
      12
    ],
    "year": 2018,
    "abstract": "Finding an ideal home is a difficult and laborious process. One of the most crucial factors in this process is the reachability between the home location and the concerned points of interest, such as places of work and recreational facilities. However, such importance is unrecognized in the extant real estate systems. By characterizing user requirements and analytical tasks in the context of finding ideal homes, we designed ReACH, a novel visual analytics system that assists people in finding, evaluating, and choosing a home based on multiple criteria, including reachability. In addition, we developed an improved data-driven model for approximating reachability with massive taxi trajectories. This model enables users to interactively integrate their knowledge and preferences to make judicious and informed decisions. We show the improvements in our model by comparing the theoretical complexities with the prior study and demonstrate the usability and effectiveness of the proposed system with task-based evaluation.",
    "paper": "source/projects/homefinder/reach.pdf",
    "video": "https://www.youtube.com/watch?v=4IIdIpIriSE",
    "embedVideo": "https://www.youtube.com/embed/4IIdIpIriSE",
    "DOI": "10.1145/3173574.3173821"
  },
  {
    "id": "SocialWave",
    "title": "SocialWave: Visual Analysis of Spatio-temporal Diffusion of Information on Social Media",
    "teaser": "source/projects/socialwave/socialwave.png",
    "authors": [
      "Guodao Sun",
      "Tan Tang",
      "Tai-Quan Peng",
      "Ronghua Liang",
      "Yingcai Wu"
    ],
    "source": "TIST",
    "transaction": "ACM Transactions on Intelligent Systems and Technology (TIST 2017)",
    "volume": 9,
    "issue": 2,
    "page": [
      1,
      23
    ],
    "year": 2017,
    "abstract": "Rapid advancement of social media tremendously facilitates and accelerates the information diffusion among users around the world. How and to what extent will the information on social media achieve widespread diffusion across the world? How can we quantify the interaction between users from different geolocations in the diffusion process? How will the spatial patterns of information diffusion change over time? To address these questions, a dynamic social gravity model (SGM) is proposed to quantify the dynamic spatial interaction behavior among social media users in information diffusion. The dynamic SGM includes three factors that are theoretically significant to the spatial diffusion of information: geographic distance, cultural proximity, and linguistic similarity. Temporal dimension is also taken into account to help detect recency effect, and ground-truth data is integrated into the model to help measure the diffusion power. Furthermore, SocialWave, a visual analytic system, is developed to support both spatial and temporal investigative tasks. SocialWave provides a temporal visualization that allows users to quickly identify the overall temporal diffusion patterns, which reflect the spatial characteristics of the diffusion network. When a meaningful temporal pattern is identified, SocialWave utilizes a new occlusion-free spatial visualization, which integrates a node-link diagram into a circular cartogram for further analysis. Moreover, we propose a set of rich user interactions that enable in-depth, multi-faceted analysis of the diffusion on social media. The effectiveness and efficiency of the mathematical model and visualization system are evaluated with two datasets on social media, namely, Ebola Epidemics and Ferguson Unrest.",
    "paper": "source/projects/socialwave/socialwave.pdf",
    "DOI": "10.1145/3106775"
  },
  {
    "id": "ArVis",
    "title": "Exploring the design space of immersive urban analytics",
    "teaser": "source/projects/arvis/arvis.png",
    "authors": [
      "Zhutian Chen",
      "Yifang Wang",
      "Tianchen Sun",
      "Xiang Gao",
      "Wei Chen",
      "Zhigeng Pan",
      "Huamin Qu",
      "Yingcai Wu"
    ],
    "source": "VI",
    "transaction": "Visual Informatics (VI 2017)",
    "volume": 1,
    "issue": 2,
    "page": [
      132,
      142
    ],
    "year": 2017,
    "abstract": "Recent years have witnessed the rapid development and wide adoption of immersive head-mounted devices, such as HTC VIVE, Oculus Rift, and Microsoft HoloLens. These immersive devices have the potential to significantly extend the methodology of urban visual analytics by providing critical 3D context information and creating a sense of presence. In this paper, we propose a theoretical model to characterize the visualizations in immersive urban analytics. Furthermore, based on our comprehensive and concise model, we contribute a typology of combination methods of 2D and 3D visualizations that distinguishes between linked views, embedded views, and mixed views. We also propose a supporting guideline to assist users in selecting a proper view under certain circumstances by considering visual geometry and spatial distribution of the 2D and 3D visualizations. Finally, based on existing work, possible future research opportunities are explored and discussed.",
    "paper": "source/projects/arvis/arvis.pdf",
    "DOI": "10.1016/j.visinf.2017.11.002"
  },
  {
    "id": "pathquery",
    "title": "Querying Massive Trajectories by Path on the Cloud",
    "teaser": "source/projects/pathquery/pathquery.png",
    "authors": [
      "Ruiyuan Li",
      "Sijie Ruan",
      "Jie Bao",
      "Yanhua Li",
      "Yingcai Wu",
      "Yu Zheng"
    ],
    "source": "SIGSPATIAL Short Paper",
    "transaction": "Proceedings of the ACM SIGSPATIAL (2017)",
    "page": [
      1,
      4
    ],
    "year": 2017,
    "abstract": "A path query aims to find the trajectories that pass a given sequence of connected road segments within a time period. It is very useful in many urban applications, e.g., 1) traffic modeling, 2) frequent path mining, and 3) traffic anomaly detection. Existing solutions for path query are implemented based on single machines, which are not efficient for the following tasks: 1) indexing large-scale historical data; 2) handling real-time trajectory updates; and 3) processing concurrent path queries. In this paper, we design and implement a cloud-based path query processing framework based on Microsoft Azure. We modify the suffix tree structure to index the trajectories using Azure Table. The proposed system consists of two main parts: 1) backend processing, which performs the pre-processing and suffix index building with distributed computing platform (i.e., Storm) used to efficiently handle massive real-time trajectory updates; and 2) query processing, which answers path queries using Azure Storm to improve efficiency and overcome the I/O bottleneck. We evaluate the performance of our proposed system based on a real taxi dataset from Guiyang, China.",
    "paper": "source/projects/pathquery/PathQuery_Zheng_SIGSPATIAL17.pdf",
    "DOI": "10.1145/3139958.3139996"
  },
  {
    "id": "IntR",
    "title": "Examining the effects of network externalities, density, and closure on in-game currency price in online games",
    "teaser": "source/projects/IntR/IntR.png",
    "authors": [
      "Xuexin Xu",
      "Xiaodong Yang",
      "Junhua Lu",
      "Ji Lan",
      "Tai-Quan Peng",
      "Yingcai Wu",
      "Wei Chen"
    ],
    "source": "Internet Research",
    "transaction": "Internet Research (2017)",
    "volume": 27,
    "issue": 4,
    "page": [
      924,
      941
    ],
    "year": 2017,
    "abstract": "Massively multiplayer online role-playing games (MMORPGs) create quasi-real social systems in which players can interact with one another, and quasi-real economic systems where players can consume and trade in-game items with virtual currency. The in-game currency price, an important indicator of a virtual economy, is highly contingent on playersâ€™ behavioral interaction in MMORPGs. The purpose of this paper is to adopt a network perspective to examine how topological characteristics of social networks in an MMORPG, namely, network externalities, density, and closure, would exert impacts on the in-game currency price. Playersâ€™ behavioral data were collected from a popular MMORPG in China on a weekly basis for 52 weeks. With a time series analytical approach, the empirical model for the price function of in-game currency was estimated with vector autoregression. The results show that the number of core avatars and network density are positively associated with in-game currency price, while network closure has a negative effect on in-game currency price. However, in-game currency price is found to have no significant relationship with the trade volume of the currency. This study fills in an important research gap by investigating factors influencing the in-game currency price of MMORPGs from a network perspective, which contributes to the existing literature of network effects and advances our understanding about how playersâ€™ interaction will influence the dynamics of a virtual economy. The findings could offer useful insights for online game companies to better understand their playersâ€™ social interaction and consumption behavior.",
    "paper": "source/projects/IntR/IntR.pdf",
    "DOI": "10.1108/IntR-07-2016-0201"
  },
  {
    "id": "SmartAdP",
    "title": "SmartAdP: Visual Analytics of Large-scale Taxi Trajectories for Selecting Billboard Locations",
    "teaser": "source/projects/smartadp/smartadp.png",
    "DOI": "10.1109/TVCG.2016.2598432",
    "authors": [
      "Dongyu Liu",
      "Di Weng",
      "Yuhong Li",
      "Jie Bao",
      "Yu Zheng",
      "Huamin Qu",
      "Yingcai Wu"
    ],
    "source": "IEEE VIS (VAST)",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (VAST 2016)",
    "volume": 23,
    "issue": 1,
    "page": [
      1,
      10
    ],
    "year": 2016,
    "abstract": "The problem of formulating solutions immediately and comparing them rapidly for billboard placements has plagued advertising planners for a long time, owing to the lack of efficient tools for in-depth analyses to make informed decisions. In this study, we attempt to employ visual analytics that combines the state-of-the-art mining and visualization techniques to tackle this problem using large-scale GPS trajectory data. In particular, we present SmartAdP, an interactive visual analytics system that deals with the two major challenges including finding good solutions in a huge solution space and comparing the solutions in a visual and intuitive manner. An interactive framework that integrates a novel visualization-driven data mining model enables advertising planners to effectively and efficiently formulate good candidate solutions. In addition, we propose a set of coupled visualizations: a solution view with metaphor-based glyphs to visualize the correlation between different solutions; a location view to display billboard locations in a compact manner; and a ranking view to present multi-typed rankings of the solutions. This system has been demonstrated using case studies with a real-world dataset and domain-expert interviews. Our approach can be adapted for other location selection problems such as selecting locations of retail stores or restaurants using trajectory data.",
    "paper": "source/projects/smartadp/smartadp.pdf",
    "video": "https://www.youtube.com/watch?v=Nkdup4YcX0A",
    "embedVideo": "https://www.youtube.com/embed/Nkdup4YcX0A"
  },
  {
    "id": "RouteMaps",
    "title": "Embedding Spatio-temporal Information into Maps by Route-Zooming",
    "teaser": "source/projects/route/route.jpg",
    "DOI": "10.1109/TVCG.2016.2535234",
    "authors": [
      "Guodao Sun",
      "Ronghua Liang",
      "Huamin Qu",
      "Yingcai Wu"
    ],
    "source": "IEEE TVCG",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics",
    "volume": 23,
    "issue": 5,
    "page": [
      1506,
      1519
    ],
    "year": 2016,
    "abstract": "Analysis and exploration of spatio-temporal data such as traffic flow and vehicle trajectories have become important in urban planning and management. In this paper, we present a novel visualization technique called route-zooming that can embed spatio-temporal information into a map seamlessly for occlusion-free visualization of both spatial and temporal data. The proposed technique can broaden a selected route in a map by deforming the overall road network. We formulate the problem of route-zooming as a nonlinear least squares optimization problem by defining an energy function that ensures the route is broadened successfully on demand while the distortion caused to the road network is minimized. The spatio-temporal information can then be embedded into the route to reveal both spatial and temporal patterns without occluding the spatial context information. The route-zooming technique is applied in two instantiations including an interactive metro map for city tourism and illustrative maps to highlight information on the broadened roads to prove its applicability. We demonstrate the usability of our spatio-temporal visualization approach with case studies on real traffic flow data. We also study various design choices in our method, including the encoding of the time direction and choices of temporal display, and conduct a comprehensive user study to validate our embedded visualization design.",
    "paper": "source/projects/road_broadening/road_broadening.pdf"
  },
  {
    "id": "PieceStack",
    "title": "PieceStack: Toward Better Understanding of Stacked Graphs",
    "teaser": "source/projects/piecestack/piecestack.jpg",
    "DOI": "10.1109/TVCG.2016.2534518",
    "authors": [
      "Tongshuang Wu",
      "Yingcai Wu",
      "Conglei Shi",
      "Huamin Qu",
      "Weiwei Cui"
    ],
    "source": "PacificVis",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics (PacificVis 2016)",
    "volume": 22,
    "issue": 6,
    "page": [
      1640,
      1651
    ],
    "year": 2016,
    "abstract": "Stacked graphs have been widely adopted in various fields, because they are capable of hierarchically visualizing a set of temporal sequences as well as their aggregation. However, because of visual illusion issues, connections between overly-detailed individual layers and overly-generalized aggregation are intercepted. Consequently, information in this area has yet to be fully excavated. Thus, we present PieceStack in this paper, to reveal the relevance of stacked graphs in understanding intrinsic details of their displayed shapes. This new visual analytic design interprets the ways through which aggregations are generated with individual layers by interactively splitting and re-constructing the stacked graphs. A clustering algorithm is designed to partition stacked graphs into sub-aggregated pieces based on trend similarities of layers. We then visualize the pieces with augmented encoding to help analysts decompose and explore the graphs with respect to their interests. Case studies and a user study are conducted to demonstrate the usefulness of our technique in understanding the formation of stacked graphs.",
    "paper": "source/projects/piecestack/piecestack.pdf"
  },
  {
    "id": "PeakVizor",
    "title": "PeakVizor: Visual Analytics of Peaks in Video Clickstreams from Massive Open Online Courses",
    "teaser": "source/projects/peakvizor/peakvizor.png",
    "DOI": "10.1109/TVCG.2015.2505305",
    "authors": [
      "Qing Chen",
      "Yuanzhe Chen",
      "Dongyu Liu",
      "Conglei Shi",
      "Yingcai Wu",
      "Huamin Qu"
    ],
    "source": "IEEE TVCG",
    "transaction": "IEEE Transactions on Visualization and Computer Graphics",
    "volume": 22,
    "issue": 10,
    "page": [
      2315,
      2330
    ],
    "year": 2016,
    "abstract": "Massive open online courses (MOOCs) aim to facilitate open-access and massive-participation education. These courses have attracted millions of learners recently. At present, most MOOC platforms record the Web log data of learner interactions with course videos. Such large amounts of multivariate data pose a new challenge in terms of analyzing online learning behaviors. Previous studies have mainly focused on the aggregate behaviors of learners from a summative view; however, few attempts have been made to conduct a detailed analysis of such behaviors. To determine complex learning patterns in MOOC video interactions, this paper introduces a comprehensive visualization system called PeakVizor. This system enables course instructors and education experts to analyze the â€œpeaksâ€ or the video segments that generate numerous clickstreams. The system features three views at different levels: the overview with glyphs to display valuable statistics regarding the peaks detected; the flow view to present spatio-temporal information regarding the peaks; and the correlation view to show the correlation between different learner groups and the peaks. Case studies and interviews conducted with domain experts have demonstrated the usefulness and effectiveness of PeakVizor, and new findings about learning behaviors in MOOC platforms have been reported.",
    "paper": "source/projects/peakvizor/peakvizor.pdf"
  },
  {
    "id": "Follower-followee",
    "title": "Follower-followee Network, Communication Networks and Vote Agreement of U.S. Members of Congress",
    "teaser": "source/projects/Follower-followee/Follower-followee.jpg",
    "DOI": "10.1177/0093650214559601",
    "authors": [
      "Tai-Quan Peng",
      "Mengchen Liu",
      "Yingcai Wu",
      "Shixia Liu"
    ],
    "source": "Communication Research",
    "transaction": "Communication Research",
    "volume": 43,
    "issue": 7,
    "page": [
      996,
      1024
    ],
    "year": 2016,
    "abstract": "The digital traces of U.S. members of congress on Twitter enable researchers to observe how these public officials interact with one another in a direct and unobtrusive manner. Using data from Twitter and other sources (e.g., roll-call vote data), this study aims to examine how members of congress connect and communicate with one another on Twitter, why they will connect and communicate with one another in such a way, and what effects such connection and communication among members of congress have on their floor vote behavior. The follower-followee and communication networks of members of congress on Twitter demonstrate a high degree of partisan homogeneity. Members of congress prefer to follow or communicate with other members who are similar to them in terms of partisanship, home state, chamber, and public concern. This condition is known as the homophily effect in social network research. However, the magnitude of the homophily effect is mitigated when the effects of endogenous networking mechanisms (i.e., reciprocity and triadic closure) in such networks are controlled. Follower-followee ties can facilitate political discourse among members of congress on Twitter, whereas both follower-followee and communication ties on Twitter increase the likelihood of vote agreement among members of congress. The theoretical, methodological, and practical implications of the findings are addressed.",
    "paper": "source/projects/Follower-followee/Follower-followee.pdf"
  }
]
